---
stepsCompleted: [1, 2, 3]
inputDocuments:
  - '_bmad-output/analysis/product-brief-farmer-power-platform-2025-12-16.md'
  - '_bmad-output/analysis/product-brief-voice-quality-advisor-2025-12-20.md'
  - '_bmad-output/analysis/tbk-kenya-tea-grading-model-specification.md'
  - '_bmad-output/architecture/index.md'
  - '_bmad-output/ux-design-specification/index.md'
---

# farmer-power-platform - Epic Breakdown

## Overview

This document provides the complete epic and story breakdown for farmer-power-platform, decomposing the requirements from the Product Briefs, UX Design, and Architecture requirements into implementable stories.

## Requirements Inventory

### Functional Requirements

**Farmer Communication (SMS/Voice IVR)**
- FR1: Farmer receives SMS within 3 hours of delivery
- FR2: SMS in local language (Swahili, Kikuyu, Luo), under 160 characters
- FR3: SMS shows Grade (stars), score, and ONE specific actionable tip
- FR4: Price impact shown in KES
- FR5: Farmer can call Voice IVR shortcode for detailed explanation
- FR6: Voice IVR plays action plan via TTS in selected language (2-3 min max)
- FR7: Voice IVR supports language selection (Swahili, Kikuyu, Luo)
- FR8: SMS includes personalization (farmer name, improvement trajectory)

**Factory Dashboard**
- FR9: Factory Manager can view farmer quality dashboard
- FR10: Dashboard filters by grade, collection point, trend
- FR11: One-click contact for problem farmers (SMS/WhatsApp)
- FR12: Daily reports auto-generated by 6 AM
- FR13: Dashboard shows "action needed" / "watch" / "wins" categorization
- FR14: Dashboard loads in < 3 seconds

**Data Ingestion API**
- FR15: API accepts END_BAG events from QC Analyzer
- FR16: API accepts POOR_QUALITY_DETECTED events to trigger AI analysis
- FR17: Batch upload supported for intermittent connectivity (queue-based retry)
- FR18: API validates incoming data schema (reject malformed)
- FR19: API returns confirmation with event ID and processing status

**Collection Model**
- FR20: Store quality grading results linked to farmer_id and bag_id
- FR21: Store images and evidence in Azure Blob Storage
- FR22: Support push mode (webhook from QC Analyzer) and pull mode (Weather API)
- FR23: Emit events to Dapr pub/sub for downstream processing

**Knowledge Model**
- FR24: Diagnose quality issues from collected data (disease, weather, technique)
- FR25: Weather Impact Analyzer correlates weather with quality (3-7 day lag)
- FR26: Disease Detection from image analysis
- FR27: Store diagnoses in Analysis DB with confidence and severity
- FR28: Aggregate events within 24-hour window per farmer before analysis

**Action Plan Model**
- FR29: Generate personalized weekly action plans for farmers
- FR30: Dual-format output: detailed report + SMS summary
- FR31: Farm-scale-aware recommendations (smallholder/medium/estate)
- FR32: Translation to farmer's preferred language
- FR33: Schedule: Monday 6 AM weekly generation

**Plantation Model**
- FR34: Store farmer master data (name, phone, national_id, farm_size, location)
- FR35: Store factory and collection point data
- FR36: Farmer registration generates unique Farmer ID (e.g., WM-4521)
- FR37: Track farmer performance history and yield metrics
- FR38: Store farmer communication preferences (pref_channel, pref_lang)

**Notification Model**
- FR39: Unified channel abstraction (SMS, Voice IVR, WhatsApp)
- FR40: SMS cost optimization with tiered strategy (GSM-7, 160/320 chars)
- FR41: Delivery assurance with retry logic (standard: 3x, critical: 6x)
- FR42: Lead farmer escalation for unreachable farmers
- FR43: Group messaging and regional broadcasts
- FR44: Inbound keyword handling (HELP, DONE, STOP, STATUS)

**AI Model**
- FR45: LangGraph orchestration of multi-agent workflows
- FR46: RAG enrichment from Pinecone knowledge base
- FR47: Triage Agent routes quality issues to specialized analyzers
- FR48: Disease Analyzer, Weather Analyzer, Technique Analyzer
- FR49: MCP Servers expose data to AI agents (Collection, Analysis, Plantation, Action Plan)

**Conversational AI Model (Voice Quality Advisor)**
- FR50: Farmer calls Voice Advisor number from any basic phone
- FR51: Identify farmer by caller ID or spoken farmer ID
- FR52: Swahili speech-to-text transcription
- FR53: Intent classification for quality-related questions
- FR54: Personalized response generation with farmer's history context
- FR55: Guided dialogue (3-5 turns max, 3 min max session)
- FR56: SMS fallback if AI cannot understand
- FR57: Streaming response for natural conversation feel (<2s perceived latency)

**TBK Grading Integration**
- FR58: Support TBK binary classification (Primary/Secondary)
- FR59: Multi-head model output: leaf_type, coarse_subtype, banji_hardness
- FR60: Bag summary with primary_percentage, leaf_type_distribution
- FR61: Grade calculation logic per TBK specification

### NonFunctional Requirements

**Performance & Scale**
- NFR1: Support 100 factories, 800,000 farms at Kenya scale
- NFR2: Process 10,000 quality events/hour (peak: 20,000)
- NFR3: Handle 100 API requests/second (peak: 200)
- NFR4: Support 500 concurrent dashboard users (peak: 1,000)
- NFR5: Process 200 LLM calls/minute (peak: 400)
- NFR6: Dashboard loads in < 3 seconds
- NFR7: Quality Event → Action Plan < 60 seconds (p95)
- NFR8: Quality Event → Farmer SMS < 5 minutes

**Reliability & Availability**
- NFR9: System availability > 99.5%
- NFR10: SMS delivery rate > 98%
- NFR11: Dashboard staleness < 30 seconds
- NFR12: Graceful degradation during cloud outages (batch sync)

**AI Accuracy**
- NFR13: AI grading accuracy ≥ 97% agreement with expert human graders
- NFR14: Within-1-grade accuracy ≥ 99%
- NFR15: Critical misgrade (Premium↔Reject confusion) < 0.1%
- NFR16: Voice STT accuracy (Swahili) > 85%
- NFR17: Intent recognition accuracy > 90%

**Cost Efficiency**
- NFR18: Monthly platform cost target: $20,000-25,000 (Kenya Phase 1)
- NFR19: Per factory cost: < $250/month
- NFR20: Per farmer cost: < $0.50/year
- NFR21: Voice Advisor cost per call: < $0.30

**Security & Compliance**
- NFR22: Data residency: Azure South Africa North region
- NFR23: Kenya Data Protection Act 2019 compliance
- NFR24: Encryption at rest (AES-256) and in transit (TLS 1.3)
- NFR25: Field-level encryption for PII (farmer name, phone, GPS)
- NFR26: OAuth2/OpenID Connect authentication
- NFR27: RBAC roles: Admin, FactoryManager, FactoryViewer, Regulator

**Observability**
- NFR28: Full observability via OpenTelemetry (logging, metrics, tracing)
- NFR29: LangChain/LangGraph traces for AI debugging
- NFR30: Cost attribution per farmer_id, factory_id, agent type

### Additional Requirements

**Architecture Requirements (from architecture/index.md)**
- AR1: Kubernetes deployment with namespace per environment (QA, PreProd, Prod)
- AR2: Dapr sidecar pattern for service invocation and pub/sub
- AR3: gRPC for inter-service communication
- AR4: BFF (Backend-for-Frontend) pattern with FastAPI
- AR5: MCP servers deployed as stateless Kubernetes pods with HPA
- AR6: Circuit breaker pattern for external API calls (Starfish, Weather)
- AR7: MongoDB Atlas for document storage
- AR8: Pinecone for vector database (RAG)
- AR9: Azure Blob Storage for images
- AR10: Azure Service Bus for pub/sub messaging
- AR11: OpenTelemetry for observability
- AR12: CQRS pattern for read/write separation in Plantation Model

**UX Design Requirements (from ux-design-specification/index.md)**
- UX1: "Command Center" design direction for Factory Manager dashboard
- UX2: Material UI v6 component library
- UX3: TBK grading format (Primary/Secondary) throughout UI
- UX4: StatusBadge, TrendIndicator, FarmerCard custom components
- UX5: LeafTypeTag component showing leaf type distribution
- UX6: SMSPreview component for message composition
- UX7: Responsive design (desktop-first, mobile-friendly)
- UX8: WCAG 2.1 AA accessibility compliance
- UX9: Low-bandwidth optimization for Kenya network conditions
- UX10: Multilingual support (English, Swahili)
- UX11: Voice IVR UX with language selection menu
- UX12: Coaching cards for leaf type education
- UX13: Demo mode with seeded data for investor presentations

### FR Coverage Map

| FR | Epic | Description |
|----|------|-------------|
| FR1-FR4, FR8 | Epic 4 | Farmer SMS Feedback |
| FR5-FR7 | Epic 7 | Voice IVR Experience |
| FR9-FR14 | Epic 3 | Factory Manager Dashboard |
| FR15-FR19 | Epic 2 | Data Ingestion API |
| FR20-FR23 | Epic 2 | Collection Model |
| FR24-FR28 | Epic 5 | Knowledge Model / Diagnosis |
| FR29-FR33 | Epic 6 | Action Plan Model |
| FR34-FR38 | Epic 1 | Plantation Model / Registration |
| FR39-FR44 | Epic 4 | Notification Model |
| FR45-FR49 | Epic 5 | AI Model |
| FR50-FR57 | Epic 8 | Conversational AI / Voice Advisor |
| FR58-FR61 | Epic 2 | TBK Grading Integration |

## Epic List

### Epic 0: Platform Infrastructure Foundation

Cross-cutting infrastructure that enables domain model services. These stories establish shared libraries, proto definitions, and foundational patterns used across all epics.

**Scope:**
- Shared proto definitions for cross-cutting concerns
- Common library utilities (fp-common, fp-proto, fp-testing)
- Infrastructure patterns that block multiple domain stories

---

#### Story 0.1: MCP gRPC Infrastructure

As a **developer implementing MCP servers**,
I want shared proto definitions, generated stubs, and client utilities for gRPC-based MCP,
So that all MCP servers follow a consistent pattern and AI agents can invoke tools via DAPR.

**Context:**
Per architecture decision (see `infrastructure-decisions.md#mcp-protocol-decision-grpc-over-json-rpc`), MCP servers use gRPC protocol instead of standard JSON-RPC to maintain unified internal communication through DAPR sidecars.

**Acceptance Criteria:**

**Given** the proto definition needs to be created
**When** I check `proto/mcp/v1/mcp_tool.proto`
**Then** it defines:
  - `McpToolService` with `ListTools` and `CallTool` RPCs
  - `ListToolsRequest`, `ListToolsResponse`, `ToolDefinition` messages
  - `ToolCallRequest`, `ToolCallResponse` messages
  - Proper package naming: `farmer_power.mcp.v1`

**Given** the proto is defined
**When** I run `make proto` or `./scripts/proto-gen.sh`
**Then** Python stubs are generated in `libs/fp-proto/fp_proto/mcp/v1/`
**And** includes: `mcp_tool_pb2.py`, `mcp_tool_pb2_grpc.py`, `mcp_tool_pb2.pyi`

**Given** AI agents need to call MCP servers
**When** I import from `fp_common.mcp`
**Then** `GrpcMcpClient` is available for raw gRPC calls via DAPR
**And** `GrpcMcpTool` is available as a LangChain `BaseTool` wrapper
**And** `McpToolRegistry` is available for tool discovery

**Given** the `GrpcMcpClient` is initialized with a DAPR app_id
**When** I call `client.call_tool("get_farmer", {"farmer_id": "WM-4521"})`
**Then** the request is routed through DAPR service invocation
**And** the response is deserialized from `ToolCallResponse`
**And** OpenTelemetry trace context is propagated

**Given** the `GrpcMcpTool` is used in a LangChain agent
**When** the LLM invokes the tool
**Then** arguments are JSON-serialized and passed to `ToolCallRequest`
**And** the result is returned as a string for LLM consumption
**And** errors are raised as `ToolExecutionError` with context

**Given** unit tests need to mock MCP servers
**When** I import from `fp_testing.mocks`
**Then** `MockMcpServer` is available to stub tool responses
**And** `mock_mcp_tool` fixture is available for pytest

**Given** a tool call fails due to network error or timeout
**When** the error is caught by `GrpcMcpClient`
**Then** a `McpToolError` is raised with: error_code, message, trace_id
**And** the error is logged with full context (app_id, tool_name, arguments)
**And** OpenTelemetry span is marked as error with exception details

**Given** a tool call fails due to invalid arguments
**When** the MCP server validates the request
**Then** a `ToolCallResponse` is returned with `success=false`
**And** `error_code` is set to `INVALID_ARGUMENTS`
**And** `error_message` describes the validation failure

**Given** a tool call fails due to downstream service unavailable
**When** the MCP server cannot reach MongoDB or other dependencies
**Then** a `ToolCallResponse` is returned with `success=false`
**And** `error_code` is set to `SERVICE_UNAVAILABLE`
**And** DAPR retry policies are respected before returning error

**Given** the infrastructure is complete
**When** I run the test suite
**Then** all unit tests pass
**And** type checking (mypy) passes with no errors

**Technical Notes:**
- Proto location: `proto/mcp/v1/mcp_tool.proto`
- Generated stubs: `libs/fp-proto/fp_proto/mcp/v1/`
- Client utilities: `libs/fp-common/fp_common/mcp/`
  - `client.py` - GrpcMcpClient
  - `tool.py` - GrpcMcpTool (LangChain wrapper)
  - `registry.py` - McpToolRegistry
  - `errors.py` - McpToolError, error codes (INVALID_ARGUMENTS, SERVICE_UNAVAILABLE, etc.)
- Test utilities: `libs/fp-testing/fp_testing/mocks/mcp_mock.py`
- Error codes defined in proto: INVALID_ARGUMENTS, SERVICE_UNAVAILABLE, TOOL_NOT_FOUND, INTERNAL_ERROR
- Reference: `_bmad-output/architecture/infrastructure-decisions.md#mcp-protocol-decision-grpc-over-json-rpc`

**Dependencies:**
- None (foundational)

**Blocks:**
- Story 1.7: Plantation Model MCP Server
- Story 2.8: Collection Model MCP Server
- Story 5.9: Knowledge Model MCP Server
- Story 6.6: Action Plan MCP Server
- Story 6.1: Action Plan Model Service Setup (MCP client usage)
- Story 8.1: Conversational AI Service Setup (MCP client usage)

**Story Points:** 3

---

### Epic 0.5: Frontend & Identity Infrastructure

Cross-cutting frontend and authentication infrastructure that enables all web applications. These stories establish the shared component library, authentication flow, and foundational frontend patterns.

**Related ADRs:** ADR-002 (Frontend Architecture), ADR-003 (Identity & Access Management)

**Scope:**
- Shared React component library (@fp/ui-components)
- Azure AD B2C configuration and auth library (@fp/auth)
- Factory Portal application scaffold
- Authentication flow (BFF pattern)
- Theme system and design tokens

---

#### Story 0.5.1: Shared Component Library Setup

As a **frontend developer**,
I want a shared React component library with the design system foundation,
So that all frontend applications have consistent UI components and styling.

**Acceptance Criteria:**

**Given** the monorepo structure is configured
**When** I create the `libs/ui-components/` package
**Then** it exports as `@fp/ui-components` via npm workspaces
**And** TypeScript is configured with strict mode
**And** Vitest is configured for component testing

**Given** the component library is created
**When** I implement the theme foundation
**Then** Material UI v6 theme is configured with TBK color palette
**And** Custom palette includes: primary (tea green), secondary (earth brown), status colors
**And** Typography scale matches UX specification (Roboto, 14px base)
**And** Spacing follows 8px grid system

**Given** the theme is configured
**When** I create the base components
**Then** `StatusBadge` component is available with variants: critical, warning, improving, excellent
**And** `TrendIndicator` shows ↑/↓/→ with color coding
**And** `LeafTypeTag` displays leaf type with TBK color coding
**And** All components have unit tests and TypeScript types

**Given** I import from `@fp/ui-components`
**When** I use components in a frontend app
**Then** tree-shaking works correctly (only imported components bundled)
**And** Theme is accessible via `ThemeProvider` wrapper

**Technical Notes:**
- Location: `libs/ui-components/`
- Build: Vite library mode with rollup
- Exports: ESM only, TypeScript declarations
- Testing: Vitest + React Testing Library
- Reference: `_bmad-output/ux-design-specification/design-system-foundation.md`

**Dependencies:**
- None (foundational)

**Story Points:** 3

---

#### Story 0.5.2: Azure AD B2C Configuration

As a **platform administrator**,
I want Azure AD B2C configured for the Farmer Power Platform,
So that users can authenticate securely with role-based access control.

**Acceptance Criteria:**

**Given** the Azure subscription is available
**When** Azure AD B2C tenant is provisioned
**Then** Tenant is created: `farmerpowerb2c.onmicrosoft.com`
**And** Custom domain configured: `auth.farmerpower.co.ke`
**And** Branding matches Farmer Power design (logo, colors)

**Given** the B2C tenant is configured
**When** user flows are created
**Then** Sign-in flow is configured (no self-registration)
**And** Password reset flow is available
**And** MFA is optional (configurable per user)

**Given** the tenant is configured
**When** application registrations are created
**Then** `factory-portal-spa` is registered (SPA, PKCE)
**And** `platform-admin-spa` is registered (SPA, PKCE)
**And** `bff-api` is registered (confidential client)
**And** API scopes are defined: `Factory.Read`, `Factory.Write`, `Platform.Admin`

**Given** custom claims are needed
**When** custom user attributes are configured
**Then** `factory_id` attribute is available
**And** `role` attribute is available (from extension attribute)
**And** Claims are included in ID token

**Given** users need to be created
**When** admin creates a user via Microsoft Graph API
**Then** User is created with local account (email + password)
**And** Role is assigned via custom attribute
**And** Welcome email is sent with temporary password

**Technical Notes:**
- B2C tier: Free (50K MAUs included)
- Token lifetime: 1 hour access, 14 days refresh
- Reference: `_bmad-output/architecture/adr/ADR-003-identity-access-management.md`
- User provisioning: Microsoft Graph API (not self-service)

**Dependencies:**
- Azure subscription

**Story Points:** 5

---

#### Story 0.5.3: Shared Auth Library

As a **frontend developer**,
I want a shared authentication library for React applications,
So that all frontend apps implement consistent authentication and authorization.

**Acceptance Criteria:**

**Given** the auth library needs to be created
**When** I create `libs/auth/`
**Then** it exports as `@fp/auth` via npm workspaces
**And** MSAL React is configured as the authentication provider
**And** TypeScript types are exported for auth context

**Given** the auth library is created
**When** I implement the `AuthProvider` component
**Then** it wraps MSAL provider with B2C configuration
**And** Silent token refresh is handled automatically
**And** Login redirect flow is implemented (PKCE)

**Given** the auth context is available
**When** I use the `useAuth` hook
**Then** `isAuthenticated` boolean is available
**And** `user` object includes: name, email, roles[], factoryId
**And** `login()` and `logout()` functions are available
**And** `getAccessToken()` returns token for API calls

**Given** role-based access is needed
**When** I use the `RequireRole` component
**Then** it renders children only if user has required role
**And** Unauthorized users are redirected to access denied page
**And** Loading state is handled during auth check

**Given** the auth flow completes
**When** tokens are received
**Then** Access token is stored securely (memory, not localStorage)
**And** Refresh token handles silent renewal
**And** OpenTelemetry traces include user context (not PII)

**Technical Notes:**
- Location: `libs/auth/`
- MSAL version: @azure/msal-react ^2.0
- Token storage: In-memory with silent refresh
- Reference: ADR-003 for B2C configuration

**Dependencies:**
- Story 0.5.2: Azure AD B2C Configuration

**Story Points:** 3

---

#### Story 0.5.4: Factory Portal Scaffold

As a **frontend developer**,
I want the Factory Portal React application scaffolded with routing and layout,
So that Factory Manager, Owner, and Admin screens can be built.

**Acceptance Criteria:**

**Given** the web folder structure exists
**When** I create `web/factory-portal/`
**Then** Vite + React + TypeScript project is initialized
**And** `@fp/ui-components` and `@fp/auth` are configured as dependencies
**And** ESLint and Prettier are configured

**Given** the project is scaffolded
**When** I configure routing
**Then** React Router v6 is configured with:
  - `/command-center` (Factory Manager)
  - `/farmers/:id` (Farmer Detail)
  - `/roi` (Factory Owner)
  - `/settings/*` (Factory Admin)
**And** Routes are protected by `RequireRole` component

**Given** routing is configured
**When** I implement the layout
**Then** Sidebar navigation shows role-appropriate menu items
**And** Header shows user name and factory name
**And** Logout button is available
**And** Layout is responsive (Material UI breakpoints)

**Given** the app is built
**When** I run `npm run build`
**Then** Production bundle is generated
**And** Bundle size is < 500KB (gzipped, excluding node_modules)
**And** Source maps are generated for debugging

**Given** the development server runs
**When** I run `npm run dev`
**Then** Hot module replacement works
**And** API proxy is configured to BFF service

**Technical Notes:**
- Location: `web/factory-portal/`
- Vite config: React plugin, path aliases
- Proxy: `/api` → BFF service URL
- Reference: ADR-002 for folder structure

**Dependencies:**
- Story 0.5.1: Shared Component Library
- Story 0.5.3: Shared Auth Library

**Story Points:** 3

---

#### Story 0.5.5: BFF Authentication Middleware

As a **backend developer**,
I want the BFF service to validate JWT tokens from Azure AD B2C,
So that API endpoints are protected with proper authorization.

**Acceptance Criteria:**

**Given** the BFF service exists (from Story 3.1)
**When** I add authentication middleware
**Then** JWT tokens are validated against B2C JWKS endpoint
**And** Token claims are extracted and available in request context
**And** Invalid tokens return 401 Unauthorized

**Given** the JWT is validated
**When** the middleware extracts claims
**Then** `user_id`, `email`, `roles[]`, `factory_id` are available
**And** Claims are added to OpenTelemetry trace context
**And** PII (email, name) is NOT logged

**Given** role-based authorization is needed
**When** I use the `@require_role` decorator
**Then** Endpoints are protected by role check
**And** Unauthorized access returns 403 Forbidden
**And** Error message does not reveal internal details

**Given** factory-level authorization is needed
**When** I use the `@require_factory` decorator
**Then** Users can only access their assigned factory's data
**And** Cross-factory access returns 403 Forbidden
**And** Platform admins bypass factory restriction

**Given** a token is expired
**When** the client sends a request
**Then** 401 is returned with `token_expired` error code
**And** Client can refresh and retry

**Technical Notes:**
- FastAPI middleware with python-jose
- JWKS caching: 24 hours
- Decorators: `@require_role`, `@require_factory`
- Reference: ADR-003 for authorization flow

**Dependencies:**
- Story 0.5.2: Azure AD B2C Configuration
- Story 3.1: Dashboard BFF Setup

**Story Points:** 3

---

### Epic 1: Farmer Registration & Data Foundation
Factory staff can register farmers into the system. Farmers receive their unique ID and are ready to be tracked.

**FRs covered:** FR34, FR35, FR36, FR37, FR38

**Scope:**
- Farmer master data storage (name, phone, national_id, farm_size, location)
- Factory and collection point data management
- Farmer ID generation (e.g., WM-4521)
- Performance history tracking structure
- Communication preferences (pref_channel, pref_lang)

---

### Epic 2: Quality Data Ingestion
QC Analyzer can submit quality grading results to the platform. Data is validated, stored, and events are emitted for downstream processing.

**FRs covered:** FR15, FR16, FR17, FR18, FR19, FR20, FR21, FR22, FR23, FR58, FR59, FR60, FR61

**Scope:**
- END_BAG event ingestion API
- POOR_QUALITY_DETECTED event handling
- Batch upload for intermittent connectivity
- TBK binary classification (Primary/Secondary)
- Multi-head model output storage (leaf_type, coarse_subtype, banji_hardness)
- Push mode (webhook) and pull mode (Weather API)
- Image storage in Azure Blob
- Event emission to Dapr pub/sub

---

### Epic 3: Factory Manager Dashboard
Factory Quality Managers can view farmer quality data, identify problem farmers, and take action. Daily reports are auto-generated.

**FRs covered:** FR9, FR10, FR11, FR12, FR13, FR14

**Scope:**
- Dashboard with farmer quality overview (Command Center design)
- Filter by grade, collection point, trend
- One-click contact for problem farmers (SMS/WhatsApp)
- Daily reports auto-generated by 6 AM
- "Action needed" / "Watch" / "Wins" categorization
- < 3 second load time
- TBK format display (Primary/Secondary percentages)

---

### Epic 4: Farmer SMS Feedback
Farmers receive personalized SMS feedback within 3 hours of delivery, with actionable tips in their local language.

**FRs covered:** FR1, FR2, FR3, FR4, FR8, FR39, FR40, FR41, FR42, FR43, FR44

**Scope:**
- SMS delivery within 3 hours of quality event
- Local language support (Swahili, Kikuyu, Luo)
- Grade (stars) + score + ONE actionable tip
- Price impact shown in KES
- Personalization (farmer name, trajectory)
- SMS cost optimization (GSM-7, tiered strategy)
- Delivery assurance with retry (standard: 3x, critical: 6x)
- Lead farmer escalation for unreachable farmers
- Inbound keyword handling (HELP, DONE, STOP, STATUS)

---

### Epic 5: Quality Diagnosis AI
Platform automatically diagnoses quality issues (disease, weather, technique) and stores analysis results for action plan generation.

**FRs covered:** FR24, FR25, FR26, FR27, FR28, FR45, FR46, FR47, FR48, FR49

**Scope:**
- Triage Agent routes to specialized analyzers
- Disease Detection from image analysis
- Weather Impact Analyzer (3-7 day lag correlation)
- Technique Assessment
- Trend Analysis
- Event aggregation (24-hour window per farmer)
- RAG enrichment from Pinecone knowledge base
- MCP Servers (Collection, Plantation, Knowledge, Action Plan)
- LangGraph workflow orchestration

---

### Epic 6: Weekly Action Plans
Farmers receive weekly personalized action plans with specific recommendations tailored to their farm size and recent quality issues.

**FRs covered:** FR29, FR30, FR31, FR32, FR33

**Scope:**
- Weekly action plan generation (Monday 6 AM schedule)
- Dual-format output (detailed report + SMS summary)
- Farm-scale-aware recommendations (smallholder/medium/estate)
- Translation to farmer's preferred language
- Empty state handling (no issues = celebration message)

---

### Epic 7: Voice IVR Experience
Farmers can call a shortcode to hear their detailed action plan via TTS in their preferred language (Swahili, Kikuyu, Luo).

**FRs covered:** FR5, FR6, FR7

**Scope:**
- Voice IVR shortcode (*384#)
- Caller ID lookup for farmer identification
- Language selection menu (press 1 for Swahili, etc.)
- TTS playback of action plans (Google Cloud TTS)
- 2-3 minute max duration
- Replay and help options

---

### Epic 8: Voice Quality Advisor (Conversational AI)
Farmers can call and have a two-way conversation about quality improvement, asking questions in Swahili and receiving personalized guidance.

**FRs covered:** FR50, FR51, FR52, FR53, FR54, FR55, FR56, FR57

**Scope:**
- Inbound voice calls from any basic phone
- Farmer identification (caller ID or spoken farmer ID)
- Swahili speech-to-text transcription
- Intent classification for quality-related questions
- Personalized response generation with farmer's history context
- Guided dialogue (3-5 turns max, 3 min max session)
- SMS fallback if AI cannot understand
- Streaming response for natural feel (<2s perceived latency)

---

## Stories

### Epic 1: Farmer Registration & Data Foundation

#### Story 1.1: Plantation Model Service Setup

As a **platform operator**,
I want the Plantation Model service deployed with Dapr sidecar and MongoDB connection,
So that farmer and factory data can be stored and accessed by other services.

**Acceptance Criteria:**

**Given** the Kubernetes cluster is running with Dapr installed
**When** the Plantation Model service is deployed
**Then** the service starts successfully with health check endpoint returning 200
**And** the Dapr sidecar is injected and connected
**And** MongoDB connection is established (verified via connection test)
**And** gRPC server is listening on port 50051
**And** OpenTelemetry traces are emitted for all operations

**Technical Notes:**
- Python FastAPI + grpcio
- Dapr state store component for MongoDB
- Health endpoint: `/health` and `/ready`
- Environment: farmer-power-{env} namespace

---

#### Story 1.2: Factory and Collection Point Management

As a **platform administrator**,
I want to create and manage factories and collection points,
So that farmers can be associated with their delivery locations.

**Acceptance Criteria:**

**Given** the Plantation Model service is running
**When** I create a new factory via gRPC API
**Then** the factory is stored with: factory_id, name, location (region, gps), contact info
**And** a unique factory_id is generated (format: KEN-FAC-XXX)

**Given** a factory exists
**When** I create a collection point for that factory
**Then** the collection point is stored with: cp_id, name, factory_id, location, clerk_id, operating_hours, collection_days, capacity
**And** a unique cp_id is generated (format: {region}-cp-XXX)

**Given** a collection point exists
**When** I query collection points by factory_id
**Then** all collection points for that factory are returned

**Given** a collection point exists
**When** I update collection point details (operating_hours, clerk_id)
**Then** the changes are persisted and returned in subsequent queries

---

#### Story 1.3: Farmer Registration

As a **collection point clerk**,
I want to register new farmers with their details,
So that farmers receive a unique ID and can deliver tea to the factory.

**Acceptance Criteria:**

**Given** a collection point exists
**When** I register a new farmer with: name, phone, national_id, farm_size_hectares, gps_location
**Then** a unique farmer_id is generated (format: WM-XXXX where X is numeric)
**And** the farmer is stored with all provided fields
**And** farm_scale is auto-calculated: smallholder (<1 ha), medium (1-5 ha), estate (>5 ha)
**And** created_at timestamp is recorded
**And** the farmer is linked to the collection_point_id

**Given** a farmer with phone number already exists
**When** I attempt to register with the same phone number
**Then** the registration fails with error "Phone number already registered"
**And** the existing farmer_id is returned for reference

**Given** a farmer is registered
**When** I query farmer by farmer_id
**Then** all farmer details are returned including calculated farm_scale

**Given** registration is complete
**When** the farmer record is created
**Then** an event "plantation.farmer.registered" is published to Dapr pub/sub
**And** the event payload includes farmer_id, phone, collection_point_id, factory_id

---

#### Story 1.4: Farmer Performance History Structure

As a **factory quality manager**,
I want farmer performance metrics tracked over time,
So that I can identify trends and target improvement efforts.

**Acceptance Criteria:**

**Given** a farmer exists in the system
**When** the farmer_performance subdocument is initialized
**Then** it contains: historical.deliveries_30d, historical.primary_percentage_30d, historical.yield_kg_per_hectare_30d, historical.yield_vs_regional_avg, historical.yield_percentile

**Given** a farmer has performance data
**When** I query get_farmer_summary(farmer_id)
**Then** the response includes: total_deliveries, avg_primary_percentage, trend (improving/stable/declining), last_delivery_date, yield metrics

**Given** new quality data arrives for a farmer
**When** the performance aggregation runs
**Then** 30-day rolling metrics are recalculated
**And** yield_vs_regional_avg is computed against regional averages
**And** the trend direction is determined (3+ deliveries required)

**Technical Notes:**
- Performance aggregation triggered by "collection.quality.received" event
- Regional averages computed per factory region
- Trend calculation: compare last 7 days avg vs previous 7 days

---

#### Story 1.5: Farmer Communication Preferences

As a **farmer**,
I want to set my preferred communication channel and language,
So that I receive feedback in a way I can understand.

**Acceptance Criteria:**

**Given** a farmer is registered
**When** the farmer record is created
**Then** default preferences are set: pref_channel = "sms", pref_lang = "sw" (Swahili)

**Given** a farmer exists
**When** I update communication preferences via API
**Then** pref_channel can be set to: "sms", "whatsapp", "voice"
**And** pref_lang can be set to: "sw" (Swahili), "ki" (Kikuyu), "luo" (Luo), "en" (English)
**And** changes are persisted immediately

**Given** a farmer's preferences are updated
**When** the Notification Model queries farmer preferences
**Then** the current pref_channel and pref_lang are returned

**Given** an invalid preference value is provided
**When** I attempt to update preferences
**Then** the update fails with validation error listing valid options

---

#### Story 1.6: TBK Quality Grading

As a **factory quality manager**,
I want tea quality grades calculated using TBK (Tea Board of Kenya) standards,
So that farmers receive consistent, industry-standard quality assessments.

**Acceptance Criteria:**

**Given** a `collection.quality_result.received` event is received from Collection Model
**When** the Plantation Model processes the event
**Then** the extracted quality data is retrieved from the event payload
**And** TBK grade is calculated based on primary_percentage and fine_leaf_percentage

**Given** quality data contains leaf_type_distribution
**When** TBK grade is calculated
**Then** the grade follows TBK specification:
  - Grade 1 (Premium): >=85% primary AND fine_leaf >=60%
  - Grade 2 (Standard): >=70% primary OR fine_leaf >=40%
  - Grade 3 (Below Standard): <70% primary AND fine_leaf <40%

**Given** a TBK grade is calculated
**When** the grade is stored
**Then** the farmer's quality record is updated with: tbk_grade, tbk_grade_code, graded_at
**And** the grade is linked to the original quality_result document_id
**And** the farmer's performance_history is updated

**Given** the grading is complete
**When** downstream services need the grade
**Then** a `plantation.quality.graded` event is emitted via DAPR Pub/Sub
**And** the event payload includes: farmer_id, document_id, tbk_grade, tbk_grade_code

**Given** invalid or incomplete quality data is received
**When** grading cannot be performed
**Then** the event is logged with error details
**And** the farmer's record is NOT updated
**And** an alert is raised for manual review

**Technical Notes:**
- Subscribe to `collection.quality_result.received` via DAPR Pub/Sub
- Grading logic is pure function (no external dependencies)
- Grade stored in farmer's `quality_grades` subcollection
- Performance history aggregation updated (rolling 30-day average)
- OpenTelemetry metrics: `plantation.grading.count`, `plantation.grading.distribution`

**Dependencies:**
- Story 2.4: Generic Content Processing Framework (emits the event)

---

#### Story 1.7: Plantation Model MCP Server

As an **AI agent**,
I want to access farmer and factory data via MCP tools,
So that I can generate personalized recommendations.

**Acceptance Criteria:**

**Given** the Plantation MCP Server is deployed
**When** an AI agent calls `get_farmer(farmer_id)`
**Then** the response includes: name, phone, farm_size_hectares, farm_scale, region, collection_point_id, pref_lang, pref_channel

**Given** a farmer_id exists
**When** an AI agent calls `get_farmer_summary(farmer_id)`
**Then** the response includes: performance metrics, trend, yield_vs_regional_avg, last_delivery_date, historical quality data

**Given** a factory_id exists
**When** an AI agent calls `get_collection_points(factory_id)`
**Then** all collection points for that factory are returned with their details

**Given** a collection_point_id exists
**When** an AI agent calls `get_farmers_by_collection_point(cp_id)`
**Then** all farmers registered at that collection point are returned

**Given** the MCP Server receives a request
**When** processing completes
**Then** OpenTelemetry traces are emitted with tool name and duration
**And** errors are logged with full context

**Technical Notes:**
- MCP Server deployed as separate Kubernetes deployment
- HPA enabled: min 2, max 10 replicas
- gRPC interface following MCP protocol
- Read-only access to MongoDB (read replicas)

---

### Epic 2: Quality Data Ingestion

#### Story 2.1: Collection Model Service Setup

As a **platform operator**,
I want the Collection Model service deployed with DAPR sidecar, MongoDB, and Redis pub/sub,
So that quality grading data can be ingested, stored, and domain events emitted to downstream services.

**Acceptance Criteria:**

**Given** the Kubernetes cluster is running with DAPR installed
**When** the Collection Model service is deployed
**Then** the service starts successfully with health check endpoint returning 200
**And** the DAPR sidecar is injected and connected
**And** MongoDB connection is established (verified via connection test)
**And** Redis pub/sub component is configured and connected
**And** OpenTelemetry traces are emitted for all operations

**Given** the service is running
**When** the DAPR pub/sub is tested
**Then** messages can be published to topics: `collection.document.stored`, `collection.poor_quality_detected`
**And** topic subscriptions are registered with DAPR

**Given** Azure Event Grid subscription is configured
**When** a blob is created in `qc-analyzer-results` or `qc-analyzer-exceptions` containers
**Then** Event Grid sends HTTP POST to the service's `/api/events/blob-created` endpoint
**And** the webhook validates Event Grid subscription handshake

**Technical Notes:**
- Python FastAPI with async handlers
- DAPR pub/sub component: Redis (internal domain events)
- External events: Azure Event Grid webhook (blob triggers)
- Health endpoints: `/health` and `/ready`
- Environment: farmer-power-{env} namespace
- Proto: `farmer_power.collection.v1`

**Infrastructure (Epic 0 prerequisite):**
- Azure Event Grid System Topic for storage account (Epic 0)
- Event subscriptions filtering on `Microsoft.Storage.BlobCreated` (Epic 0)
- Webhook endpoint configured after service deployment

---

#### Story 2.2: Source Configuration CLI

As a **platform operator**,
I want a CLI tool to manage data source configurations,
So that new data sources can be onboarded without code changes.

**Acceptance Criteria:**

**Given** the `fp-source-config` CLI is installed
**When** I run `fp-source-config deploy sources.yaml`
**Then** the YAML file is validated against the SourceConfig schema
**And** configurations are upserted to MongoDB collection `source_configs`
**And** a summary is printed: sources added, updated, unchanged

**Given** a source configuration YAML file
**When** I run `fp-source-config validate sources.yaml`
**Then** the file is validated without deploying
**And** validation errors are printed with line numbers
**And** exit code is 0 for valid, 1 for invalid

**Given** source configurations exist in MongoDB
**When** I run `fp-source-config list`
**Then** all configured sources are listed with: source_id, source_type, trigger_mode, status

**Given** a source_id exists
**When** I run `fp-source-config get <source_id>`
**Then** the full configuration is printed as YAML

**Given** a source_id exists
**When** I run `fp-source-config disable <source_id>`
**Then** the source is marked inactive (enabled: false)
**And** no new ingestion jobs will be triggered for this source

**Technical Notes:**
- CLI framework: Typer
- Config schema defined in `fp-common` as Pydantic models
- MongoDB collection: `source_configs`
- SourceConfig fields: source_id, source_type, trigger_mode, container_pattern, llm_extraction_prompt_id, enabled

---

#### Story 2.3: Event Grid Trigger Handler

As a **Collection Model service**,
I want to receive Azure Event Grid blob-created events,
So that new QC Analyzer uploads trigger automatic ingestion.

**Acceptance Criteria:**

**Given** the Collection Model service is running
**When** Event Grid sends a subscription validation request
**Then** the service responds with the validationResponse
**And** the subscription is confirmed

**Given** a blob is created in `qc-analyzer-results` container
**When** Event Grid sends blob-created event
**Then** the event is parsed: container, blob_path, content_length, timestamp
**And** source_config is looked up by container pattern match
**And** if source is enabled, ingestion job is queued

**Given** the blob matches source_config with trigger_mode=BLOB_TRIGGER
**When** the event is processed
**Then** blob metadata is extracted: source_type, device_id (from path)
**And** processing_status is set to "queued" in MongoDB
**And** the blob is queued for content processing

**Given** no source_config matches the blob container
**When** the event is processed
**Then** the event is logged with warning "No matching source config"
**And** no further processing occurs
**And** metrics track unmatched events

**Given** the same blob event is received twice (Event Grid retry)
**When** processing is attempted
**Then** idempotency check detects duplicate (by blob_path + etag)
**And** duplicate is skipped with log "Already processed"

**Technical Notes:**
- Endpoint: POST `/api/events/blob-created`
- Event Grid schema: EventGridEvent or CloudEvents v1.0
- Idempotency: MongoDB unique index on (blob_path, blob_etag)
- Async processing: queue to internal task queue after validation

---

#### Story 2.4: Generic Content Processing Framework + JSON Processor

As a **platform operator**,
I want a generic, configuration-driven content processing framework,
So that new data sources can be processed without code changes to the core pipeline.

As a **platform data analyst**,
I want QC Analyzer JSON results automatically ingested,
So that bag summaries and grading data are stored for analysis.

**Acceptance Criteria:**

**Framework (Generic):**

**Given** an ingestion job is dequeued for processing
**When** the processor is selected
**Then** the `transformation.agent` field from SourceConfig determines which ContentProcessor is used
**And** no hardcoded source_type checks exist in the pipeline
**And** the ProcessorRegistry returns the appropriate processor class

**Given** a new source type needs to be added
**When** a developer implements ContentProcessor
**Then** they only need to:
  1. Create a new processor class implementing `ContentProcessor` ABC
  2. Register it in `ProcessorRegistry` with the `transformation.agent` key
  3. Add source configuration YAML with matching `transformation.agent`
**And** no changes to the core pipeline code are required

**Given** an unknown `transformation.agent` value is encountered
**When** the processor lookup fails
**Then** processing_status is set to "failed"
**And** error details include: "No processor registered for agent: {agent_name}"
**And** the job is not retried (configuration error, not transient)

**JSON Processor (QC Analyzer Results):**

**Given** a JSON blob is queued for processing
**When** the `JsonExtractionProcessor` is invoked
**Then** the blob is downloaded from Azure Blob Storage (async streaming)
**And** the raw JSON is stored in `raw_documents` collection
**And** processing_status is updated to "extracting"

**Given** the raw JSON is stored
**When** LLM extraction runs with the configured prompt (from `transformation.llm_prompt_id`)
**Then** structured data is extracted: bag_id, farmer_id, collection_point_id, timestamp, overall_classification, leaf_assessments[]
**And** bag_summary is calculated: primary_percentage, leaf_type_distribution, overall_grade
**And** extracted data is stored in `quality_events` collection

**Given** leaf_type_distribution is calculated
**When** the TBK grade is determined
**Then** the grade follows the TBK specification:
  - Grade 1 (Premium): ≥85% primary AND fine_leaf ≥60%
  - Grade 2 (Standard): ≥70% primary OR fine_leaf ≥40%
  - Grade 3 (Below Standard): <70% primary AND fine_leaf <40%

**Given** extraction succeeds
**When** the quality_event is stored
**Then** a `collection.document.stored` domain event is emitted via Redis pub/sub
**And** processing_status is updated to "completed"
**And** the event payload includes: document_id, source_id, farmer_id

**Given** LLM extraction fails
**When** error is detected
**Then** processing_status is set to "failed"
**And** error details are stored: error_type, error_message, retry_count
**And** document is queued for retry (max 3 attempts)

**Technical Notes:**

**Framework Architecture:**
```
processors/
├── __init__.py
├── base.py              # ContentProcessor ABC, ProcessorResult
├── registry.py          # ProcessorRegistry (agent → processor mapping)
├── json_extraction.py   # JsonExtractionProcessor
└── zip_extraction.py    # ZipExtractionProcessor (Story 2.5)
```

**ContentProcessor ABC:**
```python
from abc import ABC, abstractmethod
from collection_model.domain.ingestion_job import IngestionJob

class ContentProcessor(ABC):
    """Base class for all content processors."""

    @abstractmethod
    async def process(
        self,
        job: IngestionJob,
        source_config: dict
    ) -> ProcessorResult:
        """Process the ingestion job according to source config."""
        pass

    @abstractmethod
    def supports_content_type(self, content_type: str) -> bool:
        """Check if processor supports the given content type."""
        pass
```

**ProcessorRegistry:**
```python
class ProcessorRegistry:
    """Maps transformation.agent values to processor classes."""

    _processors: dict[str, type[ContentProcessor]] = {}

    @classmethod
    def register(cls, agent_name: str, processor_class: type[ContentProcessor]):
        cls._processors[agent_name] = processor_class

    @classmethod
    def get_processor(cls, agent_name: str) -> ContentProcessor:
        if agent_name not in cls._processors:
            raise ProcessorNotFoundError(f"No processor for agent: {agent_name}")
        return cls._processors[agent_name]()

# Registration (in __init__.py or startup)
ProcessorRegistry.register("collection-json-extraction", JsonExtractionProcessor)
ProcessorRegistry.register("collection-zip-extraction", ZipExtractionProcessor)
```

**Pipeline Integration:**
```python
# In content_processor_worker.py - NO hardcoded source checks
async def process_job(job: IngestionJob, source_config: dict):
    agent = source_config["transformation"]["agent"]
    processor = ProcessorRegistry.get_processor(agent)  # Pure config-driven
    result = await processor.process(job, source_config)
    return result
```

- Azure Blob SDK: async download with streaming
- LLM extraction via OpenRouter (prompt from MongoDB `prompts` collection)
- MongoDB collections: raw_documents, quality_events
- Deduplication handled in Story 2.6

---

#### Story 2.5: ZIP Content Processor for Exception Images

As a **Knowledge Model AI agent**,
I want secondary leaf exception images automatically extracted and stored,
So that I can analyze poor quality samples with visual evidence.

**Acceptance Criteria:**

**Given** the Generic Content Processing Framework exists (Story 2.4)
**When** a ZIP blob is queued for processing with `processor_type: zip-extraction`
**Then** the `ZipExtractionProcessor` is selected via source config
**And** no changes to the core pipeline are required

**Given** the `ZipExtractionProcessor` is invoked
**When** the blob is downloaded
**Then** the ZIP is extracted in memory (streaming, no disk write)
**And** `manifest.json` is validated against `generic-zip-manifest.schema.json`
**And** `payload` is validated against source-specific schema (`qc-exceptions-manifest.json`)

**Given** the manifest contains documents with file roles
**When** files are processed per `manifest.documents[]`
**Then** files with `role: image` are extracted to `exception-images` container
**And** blob path follows: `exception-images/{plantation_id}/{batch_id}/{document_id}.jpg`
**And** files with `role: metadata` are parsed and merged into document attributes

**Given** images and metadata are extracted
**When** documents are stored
**Then** a `DocumentIndex` is created in the `documents` collection for each manifest document
**And** `linkage_fields` contains: `plantation_id`, `batch_id`, `factory_id`, `batch_result_ref`
**And** `extracted_fields` contains image attributes: `quality_grade`, `confidence`, `leaf_type`, `coarse_subtype`
**And** `raw_document` references the original ZIP blob

**Given** all documents are stored
**When** processing completes
**Then** a `collection.quality-exceptions.ingested` domain event is emitted
**And** processing_status is updated to "completed"
**And** the event payload includes: `document_id`, `source_id`, `plantation_id`, `batch_id`, document count

**Given** the ZIP is corrupted or invalid
**When** extraction fails
**Then** processing_status is set to "failed"
**And** error details logged: "Invalid ZIP format" or "Missing manifest.json" or schema validation errors
**And** original blob is retained for manual review

**Technical Notes:**
- Implements `ContentProcessor` ABC from Story 2.4
- Registered as: `ProcessorRegistry.register("zip-extraction", ZipExtractionProcessor)`
- ZIP processing: zipfile module with streaming (no temp files)
- Max ZIP size: 50MB
- Max images per ZIP: 100
- Image formats: JPEG, PNG only
- Uses generic ZIP manifest format (see `collection-model-architecture.md`)
- All documents stored in single `documents` collection, differentiated by `source_id`
- Linking via `linkage_fields.batch_id` and `linkage_fields.plantation_id`
- No changes to core pipeline - pure configuration-driven polymorphism

---

#### Story 2.6: Document Storage & Deduplication

As a **platform operator**,
I want duplicate documents detected and rejected,
So that storage is efficient and downstream analysis is not skewed.

**Acceptance Criteria:**

**Given** a document is about to be stored
**When** content hash (SHA-256) is calculated
**Then** the hash is checked against existing documents in MongoDB
**And** if duplicate found, storage is skipped with status "duplicate"

**Given** a duplicate document is detected
**When** the ingestion completes
**Then** no domain event is emitted
**And** response indicates: duplicate=true, original_document_id
**And** metrics track duplicate rate per source

**Given** a unique document is stored
**When** content hash is saved
**Then** MongoDB unique index on content_hash prevents race conditions
**And** document includes: content_hash, source_id, blob_path, stored_at

**Given** documents are stored over time
**When** storage metrics are queried
**Then** metrics include: total_documents, duplicates_rejected, storage_bytes, by_source breakdown

**Technical Notes:**
- Hash algorithm: SHA-256 on raw blob content
- MongoDB unique index: { content_hash: 1 }
- Duplicate detection before LLM extraction (save costs)
- Collection: raw_documents with content_hash field

---

#### Story 2.7: Scheduled Pull Ingestion Framework

As a **platform operator**,
I want a generic scheduled pull framework for external API data,
So that any HTTP/REST data source can be ingested via configuration without code changes.

**Design Principle:** Pull mode is a data fetcher that feeds JSON into the existing ingestion pipeline. The `JsonExtractionProcessor` handles all downstream processing (deduplication, AI extraction, storage, events). New data sources require only configuration - no code changes.

**Acceptance Criteria:**

**DAPR Job Lifecycle Management:**

**Given** a source is configured with `ingestion.mode: scheduled_pull`
**When** the Collection Model service starts
**Then** `JobRegistrationService.sync_all_jobs()` registers DAPR Jobs for all pull sources
**And** each job is registered with the configured schedule (cron or period)

**Given** a new pull source configuration is created via CLI
**When** the configuration is saved to MongoDB
**Then** a DAPR Job is automatically registered for the new source
**And** the job uses the schedule from `ingestion.schedule`

**Given** a pull source configuration is updated
**When** the schedule or endpoint changes
**Then** the existing DAPR Job is deleted and re-registered with new settings

**Pull Job Execution:**

**Given** a DAPR Job triggers at scheduled time
**When** `PullJobHandler` receives the job event
**Then** the source configuration is loaded from MongoDB
**And** the iteration block is checked for dynamic multi-fetch

**Given** the source has NO iteration block
**When** the job executes
**Then** a single HTTP request is made to the configured endpoint
**And** the JSON response is passed to `JsonExtractionProcessor` pipeline

**Given** the source has an iteration block
**When** the job executes
**Then** the MCP tool specified in `source_mcp`:`source_tool` is called
**And** for each item returned, a parallel fetch is executed (limited by `concurrency`)
**And** each fetched JSON is passed to `JsonExtractionProcessor` with injected linkage

**HTTP Fetch with Secrets:**

**Given** a pull source requires authentication
**When** fetching data from the endpoint
**Then** the API key is retrieved from DAPR Secret Store using `secret_store` and `secret_key`
**And** the key is added to the request header specified in `auth_header`

**Given** the HTTP request fails
**When** error is detected
**Then** retry with exponential backoff (max attempts from `retry.max_attempts`)
**And** if iteration mode, skip failed item and continue others
**And** metrics track success/failure per source

**Pipeline Reuse:**

**Given** JSON content is fetched from an external API
**When** passed to the ingestion pipeline
**Then** `RawDocumentStore` computes content hash for deduplication (Story 2-6)
**And** duplicate content returns `is_duplicate=True` without LLM costs
**And** new content proceeds through `JsonExtractionProcessor`
**And** `StorageMetrics` records stored/duplicate counts
**And** domain event is emitted via `DaprEventPublisher`

**Technical Implementation:**

| Component | Type | Description |
|-----------|------|-------------|
| `JobRegistrationService` | NEW | Register/update/delete DAPR Jobs on startup + config changes |
| `PullJobHandler` | NEW | Handle DAPR Job triggers with iteration support |
| `PullDataFetcher` | NEW | HTTP client with DAPR Secrets, URL templating |
| `IterationResolver` | NEW | Call MCP tools to get iteration items |
| `SourceConfigService` | MODIFIED | Hook job registration into config CRUD |
| `IngestionJob.content` | MODIFIED | Optional field for inline content (vs blob_path) |
| `IngestionJob.linkage` | MODIFIED | Optional injected linkage from iteration context |

**Source Configuration Schema:**

```yaml
source_id: weather-api
ingestion:
  mode: scheduled_pull
  schedule: "0 6 * * *"  # Cron or "@every 6h"
  request:
    base_url: https://api.open-meteo.com/v1/forecast
    auth_type: none | api_key | oauth
    secret_store: azure-keyvault  # DAPR secret store name
    secret_key: weather-api-key   # Key in secret store
    auth_header: X-API-Key        # Header to add
    parameters:
      hourly: temperature_2m,precipitation
      timezone: Africa/Nairobi
    timeout_seconds: 30
  iteration:  # Optional - enables multi-fetch
    foreach: region
    source_mcp: plantation-mcp
    source_tool: list_active_regions
    concurrency: 5
  retry:
    max_attempts: 3
    backoff: exponential
transformation:
  ai_agent_id: weather-data-extraction-agent
  link_field: region_id
  # ... same as blob trigger sources
storage:
  # ... same as blob trigger sources
events:
  # ... same as blob trigger sources
```

**Reused Components (no changes):**
- `JsonExtractionProcessor` - processes fetched JSON
- `RawDocumentStore` - deduplication via content hash
- `StorageMetrics` - OTel counters (Story 2-6)
- `DaprEventPublisher` - domain event emission
- `DocumentRepository` - index storage

**DAPR Secret Store Configuration:**

Secrets (API keys, OAuth credentials) are accessed via DAPR Secret Store component. This provides:
- Abstraction over secret backends (Azure Key Vault, Kubernetes Secrets, HashiCorp Vault)
- No secrets in source configuration or environment variables
- Automatic secret rotation support (backend-dependent)

**DAPR Component Definition** (`deploy/dapr/components/secretstore.yaml`):

```yaml
apiVersion: dapr.io/v1alpha1
kind: Component
metadata:
  name: azure-keyvault
  namespace: farmer-power
spec:
  type: secretstores.azure.keyvault
  version: v1
  metadata:
    - name: vaultName
      value: "farmer-power-secrets"
    - name: azureClientId
      value: ""  # Uses Managed Identity in AKS
    - name: azureTenantId
      value: ""  # From Azure AD
```

**Alternative: Kubernetes Secrets** (for local/dev):

```yaml
apiVersion: dapr.io/v1alpha1
kind: Component
metadata:
  name: kubernetes-secrets
  namespace: farmer-power
spec:
  type: secretstores.kubernetes
  version: v1
  metadata: []
```

**Usage in Source Config:**

```yaml
ingestion:
  request:
    auth_type: api_key
    secret_store: azure-keyvault    # DAPR component name
    secret_key: starfish-api-key    # Key name in secret store
    auth_header: Authorization      # HTTP header to populate
```

**Code Implementation:**

```python
# PullDataFetcher retrieves secret via DAPR client
async def _get_auth_header(self, pull_config: dict) -> dict[str, str]:
    if pull_config.get("auth_type") == "none":
        return {}

    secret_store = pull_config["secret_store"]
    secret_key = pull_config["secret_key"]
    auth_header = pull_config["auth_header"]

    # DAPR Secret Store API
    secret = await self._dapr.get_secret(
        store_name=secret_store,
        key=secret_key,
    )

    return {auth_header: secret[secret_key]}
```

**Test Validation:**
- Weather API source config (Open-Meteo, no auth, with iteration)
- Mock MCP tool returns region list
- Verify parallel fetch with concurrency limit
- Verify deduplication prevents duplicate processing
- Verify DAPR Job registration on startup and config change

---

#### Story 2.8: Market Prices Pull Mode

**Status:** COVERED BY STORY 2.7

This story is now a **configuration-only task** - no code changes required.

The generic Scheduled Pull Ingestion Framework (Story 2.7) supports any HTTP/REST data source via configuration. Market prices ingestion requires only:

1. Create source configuration YAML with `mode: scheduled_pull`
2. Configure Starfish API endpoint and authentication
3. Create AI extraction agent for market price fields
4. Register configuration via CLI

**Example Configuration:**

```yaml
source_id: market-prices-starfish
display_name: Starfish Kenya Tea Auction Prices
ingestion:
  mode: scheduled_pull
  schedule: "0 7 * * *"  # Daily 7 AM EAT
  request:
    base_url: https://api.starfish.co.ke/v1/tea-auction/prices
    auth_type: api_key
    secret_store: azure-keyvault
    secret_key: starfish-api-key
    auth_header: Authorization
    parameters:
      market: mombasa
      date: today
    timeout_seconds: 30
  retry:
    max_attempts: 3
    backoff: exponential
transformation:
  ai_agent_id: market-prices-extraction-agent
  extract_fields:
    - commodity
    - region
    - price
    - currency
    - unit
    - auction_date
  link_field: region
storage:
  raw_container: market-data-raw
  index_collection: documents
events:
  on_success:
    topic: collection.market_prices.updated
    payload_fields: [commodity, region, price, auction_date]
```

**Note:** This story remains in `unscoped-phase2` in sprint-status.yaml as it depends on Starfish API access being available. When ready, implementation is configuration-only.

---

#### Story 2.9: Collection Model MCP Server

As an **AI agent**,
I want to access quality collection data via MCP tools,
So that I can analyze quality patterns and generate recommendations.

**Acceptance Criteria:**

**Given** the Collection MCP Server is deployed
**When** an AI agent calls `get_recent_quality_events(farmer_id, days=7)`
**Then** the response includes all quality events for that farmer in the past 7 days
**And** each event includes: event_id, timestamp, primary_percentage, leaf_type_distribution, grade

**Given** a farmer_id exists
**When** an AI agent calls `get_quality_summary(farmer_id, days=30)`
**Then** the response includes: avg_primary_percentage, trend, total_deliveries, grade_distribution

**Given** an event_id exists
**When** an AI agent calls `get_quality_event(event_id)`
**Then** the full event is returned including leaf_assessments and bag_summary

**Given** the Knowledge Model needs poor quality events
**When** an AI agent calls `list_poor_quality_events(since_date, analyzed=false)`
**Then** events matching criteria are returned with farmer context

**Given** an event needs image analysis
**When** an AI agent calls `get_image_urls(event_id)`
**Then** fresh SAS URLs are returned for all images in that event
**And** URLs are valid for 1 hour

**Given** weather correlation is needed
**When** an AI agent calls `get_weather_for_region(region_id, date_range)`
**Then** weather data is returned for the specified region and date range

**Given** market prices are needed
**When** an AI agent calls `get_market_prices(commodity, region, days=30)`
**Then** price history is returned for the specified criteria

**Technical Notes:**
- MCP Server: stateless, deployed as separate Kubernetes deployment
- HPA enabled: min 2, max 10 replicas
- Read-only access to MongoDB (read replicas preferred)
- Image URL generation: Azure Blob Storage SDK for SAS tokens
- Proto: `farmer_power.collection_mcp.v1`

---

#### Story 2.10: Domain Event Emission

As a **downstream service (Knowledge Model, Engagement Model)**,
I want to subscribe to Collection domain events via Redis pub/sub,
So that I can react to new quality data in real-time.

**Acceptance Criteria:**

**Given** a quality_event is stored successfully
**When** processing completes
**Then** a `collection.document.stored` event is published to Redis pub/sub
**And** the event payload includes: document_id, source_type, farmer_id, timestamp

**Given** a poor quality event is detected (primary_percentage < 70%)
**When** the quality_event is stored
**Then** a `collection.poor_quality_detected` event is also published
**And** the event includes: event_id, farmer_id, primary_percentage, leaf_type_distribution

**Given** a critical quality issue (primary_percentage < 40%)
**When** the event is published
**Then** the event includes priority: "critical"
**And** the Knowledge Model can prioritize analysis

**Given** weather data is updated for a region
**When** storage completes
**Then** a `collection.weather.updated` event is published
**And** the event includes: region_id, date_range, data_points_count

**Given** market prices are updated
**When** storage completes
**Then** a `collection.market_prices.updated` event is published
**And** the event includes: commodity, region, latest_price, price_change_pct

**Given** a downstream service subscribes to events
**When** events are published
**Then** DAPR pub/sub delivers with at-least-once semantics
**And** events include correlation_id for tracing
**And** schema version is included for compatibility (v1)

**Technical Notes:**
- DAPR pub/sub component: Redis
- Topics: collection.document.stored, collection.poor_quality_detected, collection.weather.updated, collection.market_prices.updated
- Event schema: CloudEvents v1.0 format
- Delivery: at-least-once (consumers must be idempotent)

---

### Epic 3: Factory Manager Dashboard

#### Story 3.1: Dashboard BFF (Backend for Frontend) Setup

As a **platform operator**,
I want a BFF service deployed to serve the Factory Manager dashboard,
So that the frontend has an optimized API layer for dashboard queries.

**Acceptance Criteria:**

**Given** the Kubernetes cluster is running
**When** the Dashboard BFF service is deployed
**Then** the service starts successfully with health check endpoint returning 200
**And** FastAPI is serving REST endpoints on port 8080
**And** OpenTelemetry traces are emitted for all requests
**And** CORS is configured for allowed dashboard origins

**Given** the BFF is running
**When** an unauthenticated request is made
**Then** the request is rejected with 401 Unauthorized
**And** the response includes WWW-Authenticate header

**Given** a Factory Manager is authenticated (OAuth2/OIDC)
**When** they request dashboard data
**Then** the BFF queries Plantation and Collection Models via gRPC
**And** data is aggregated and transformed for frontend consumption
**And** only data for factories the user has access to is returned

**Given** the BFF receives multiple concurrent requests
**When** processing under load
**Then** connection pooling is used for downstream gRPC calls
**And** request timeout is enforced (5 seconds max)
**And** circuit breaker trips after 5 consecutive failures

**Technical Notes:**
- Python FastAPI with async support
- OAuth2 token validation via Azure AD B2C
- gRPC clients with connection pooling
- Environment: farmer-power-{env} namespace

---

#### Story 3.2: Farmer Quality Overview Grid

As a **Factory Quality Manager**,
I want to see a grid of all farmers with their quality metrics,
So that I can quickly assess the quality situation across my factory.

**Acceptance Criteria:**

**Given** I am logged into the Factory Manager dashboard
**When** I view the Farmer Overview page
**Then** I see a grid of FarmerCards with: farmer_name, farmer_id, primary_percentage, trend_indicator, last_delivery_date, grade_badge
**And** the grid loads in < 3 seconds
**And** farmers are sorted by primary_percentage ascending (worst first) by default

**Given** the farmer grid is displayed
**When** a farmer has TBK grading data
**Then** the FarmerCard shows: primary_percentage (large), leaf_type_distribution (LeafTypeTag components), overall_grade (StatusBadge)

**Given** the farmer grid is displayed
**When** a farmer's trend is "improving"
**Then** a green TrendIndicator (↑) is shown
**When** a farmer's trend is "stable"
**Then** a gray TrendIndicator (→) is shown
**When** a farmer's trend is "declining"
**Then** a red TrendIndicator (↓) is shown

**Given** the grid shows 500+ farmers
**When** I scroll through the list
**Then** virtualized rendering ensures smooth scrolling
**And** only visible cards are rendered in the DOM
**And** memory usage remains stable

**Given** I click on a FarmerCard
**When** the detail panel opens
**Then** I see: full farmer details, 30-day quality history chart, recent deliveries list, communication history

**Technical Notes:**
- React with Material UI v6
- React-virtualized for large lists
- FarmerCard, StatusBadge, TrendIndicator, LeafTypeTag custom components
- API endpoint: GET /api/farmers?factory_id={id}&page={n}&size={s}

---

#### Story 3.3: Farmer Categorization (Action Needed/Watch/Wins)

As a **Factory Quality Manager**,
I want farmers automatically categorized by status,
So that I can prioritize my attention on those needing help.

**Acceptance Criteria:**

**Given** a farmer has primary_percentage < 60% in last 7 days
**When** the dashboard loads
**Then** the farmer is categorized as "Action Needed" (red badge)
**And** appears at the top of the priority list

**Given** a farmer has primary_percentage 60-75% OR declining trend
**When** the dashboard loads
**Then** the farmer is categorized as "Watch" (amber badge)
**And** appears in the middle priority section

**Given** a farmer has primary_percentage > 75% AND stable/improving trend
**When** the dashboard loads
**Then** the farmer is categorized as "Wins" (green badge)
**And** appears in the success section

**Given** the dashboard shows categorized farmers
**When** I view the "Command Center" layout
**Then** I see three columns: Action Needed (left), Watch (center), Wins (right)
**And** each column shows count badge (e.g., "23 farmers")
**And** I can collapse/expand each column

**Given** a farmer's category changes
**When** new quality data arrives (via WebSocket)
**Then** the farmer moves to the new category with animation
**And** the category counts update in real-time

**Given** no farmers are in a category
**When** I view that category column
**Then** an empty state message is shown (e.g., "No farmers need immediate action - great work!")

**Technical Notes:**
- Categorization logic runs in BFF (not frontend)
- WebSocket for real-time updates (optional enhancement)
- Category thresholds configurable per factory

---

#### Story 3.4: Dashboard Filtering

As a **Factory Quality Manager**,
I want to filter farmers by various criteria,
So that I can focus on specific segments of my farmer base.

**Acceptance Criteria:**

**Given** I am on the Farmer Overview page
**When** I select a grade filter (Grade 1, Grade 2, Grade 3)
**Then** only farmers with that grade are displayed
**And** the filter chip is shown in the active filters bar

**Given** I am on the Farmer Overview page
**When** I select a collection point filter
**Then** only farmers from that collection point are displayed
**And** the collection point dropdown shows all CPs for my factory

**Given** I am on the Farmer Overview page
**When** I select a trend filter (Improving, Stable, Declining)
**Then** only farmers with that trend are displayed

**Given** I am on the Farmer Overview page
**When** I select a date range filter
**Then** metrics are recalculated for that date range
**And** "Last 7 days", "Last 30 days", "Custom range" options are available

**Given** multiple filters are applied
**When** I view the results
**Then** filters are combined with AND logic
**And** the result count updates dynamically
**And** I can clear individual filters or "Clear all"

**Given** filters are applied
**When** I refresh the page
**Then** filters are persisted in URL query parameters
**And** the same view is restored on refresh

**Technical Notes:**
- Filters stored in URL: ?grade=2&cp=KEN-cp-001&trend=declining
- BFF endpoint: GET /api/farmers?factory_id=...&grade=...&cp=...&trend=...
- Material UI FilterChip components

---

#### Story 3.5: One-Click Farmer Contact

As a **Factory Quality Manager**,
I want to quickly contact problem farmers,
So that I can follow up on quality issues without leaving the dashboard.

**Acceptance Criteria:**

**Given** I am viewing a FarmerCard or farmer detail panel
**When** I click the "Contact" button
**Then** a contact options menu appears: SMS, WhatsApp, Call

**Given** I select "SMS" contact option
**When** I click it
**Then** the SMSPreview component opens
**And** it shows a pre-filled message template based on farmer's quality issues
**And** I can edit the message before sending
**And** the send button triggers the Notification Model API

**Given** I select "WhatsApp" contact option
**When** I click it
**Then** a WhatsApp deep link opens with pre-filled message
**And** the farmer's phone number is auto-populated
**And** the message template includes farmer name and recent quality issue

**Given** I select "Call" contact option
**When** I click it
**Then** the farmer's phone number is copied to clipboard
**And** a toast notification confirms "Phone number copied"
**And** (optional) a tel: link opens the phone dialer

**Given** I send an SMS from the dashboard
**When** the message is sent successfully
**Then** a success toast appears: "SMS sent to {farmer_name}"
**And** the contact is logged in the farmer's communication history
**And** I can view the sent message in the detail panel

**Given** I send an SMS and it fails
**When** the error occurs
**Then** an error toast appears with reason
**And** I have option to retry
**And** the failed attempt is logged

**Technical Notes:**
- SMS via Notification Model gRPC API
- WhatsApp: wa.me/{phone}?text={encoded_message}
- SMSPreview component from UX spec
- Contact logging via Collection Model event

---

#### Story 3.6: Daily Report Auto-Generation

As a **Factory Quality Manager**,
I want daily summary reports generated automatically,
So that I have a quality overview waiting for me each morning.

**Acceptance Criteria:**

**Given** it is 6:00 AM in the factory's timezone
**When** the scheduled report job runs
**Then** a daily summary report is generated for each factory
**And** the report includes: date, factory_name, total_farmers, total_deliveries, avg_primary_percentage, category_counts (Action/Watch/Wins)

**Given** a daily report is generated
**When** the report is created
**Then** it includes: top 10 problem farmers (by declining primary_percentage), top 5 improving farmers (success stories), collection point comparison

**Given** a daily report is generated
**When** I view the Reports section in the dashboard
**Then** the report is available as a card with: date, summary stats, "View Full Report" button, "Download PDF" button

**Given** I click "Download PDF"
**When** the PDF is generated
**Then** the PDF is formatted with factory branding
**And** it includes all report sections with charts
**And** file name format: {factory_id}_daily_report_{date}.pdf

**Given** the report generation fails
**When** the scheduled job encounters an error
**Then** the error is logged with full context
**And** an alert is sent to platform operators
**And** the previous day's report remains available

**Given** no quality data was received yesterday
**When** the report is generated
**Then** the report shows "No deliveries recorded" with appropriate messaging
**And** trend comparisons show week-over-week instead

**Technical Notes:**
- Dapr Jobs component for 6 AM scheduling (per-factory timezone)
- PDF generation via WeasyPrint or similar
- Reports stored in Azure Blob Storage
- Report retention: 90 days

---

#### Story 3.7: Dashboard Performance Optimization

As a **Factory Quality Manager**,
I want the dashboard to load quickly even with large datasets,
So that I can efficiently review quality data without waiting.

**Acceptance Criteria:**

**Given** the dashboard has 5000+ farmers in the system
**When** I load the Farmer Overview page
**Then** the initial load completes in < 3 seconds
**And** the first 50 farmer cards are rendered
**And** remaining data loads progressively as I scroll

**Given** the BFF receives a dashboard request
**When** processing the request
**Then** read replica MongoDB connections are used
**And** commonly accessed data is cached (5-minute TTL)
**And** complex aggregations run on pre-computed materialized views

**Given** I apply filters on the dashboard
**When** the filtered results are requested
**Then** the response time is < 1 second
**And** the UI shows a loading skeleton during fetch

**Given** the dashboard is idle for 5+ minutes
**When** new quality data arrives
**Then** a subtle notification appears: "New data available - Click to refresh"
**And** data is not auto-refreshed (to avoid jarring changes during viewing)

**Given** the dashboard is under heavy load (1000 concurrent users)
**When** requests are processed
**Then** response times remain < 5 seconds (p95)
**And** HPA scales BFF pods appropriately
**And** no requests are dropped

**Given** a downstream service is unavailable
**When** the dashboard loads
**Then** available data is still displayed
**And** unavailable sections show "Data temporarily unavailable"
**And** the page does not crash

**Technical Notes:**
- Redis cache for hot data (farmer summaries, category counts)
- Materialized views for aggregations (updated every 5 min)
- Pagination: cursor-based for large result sets
- Error boundaries in React for graceful degradation

---

#### Story 3.8: Factory Owner ROI Dashboard

As a **Factory Owner**,
I want to see ROI metrics and value validation for my subscription,
So that I can justify the platform investment to stakeholders.

**Acceptance Criteria:**

**Given** I am logged in as Factory Owner
**When** I navigate to the ROI Summary page
**Then** I see key metrics: quality improvement %, reject reduction, farmer retention
**And** Cost savings are calculated in KES
**And** Trend comparison shows month-over-month improvement
**And** Page loads in < 3 seconds

**Given** I am viewing ROI metrics
**When** I click on a metric card
**Then** I drill down to detailed breakdown (by collection point, by farmer segment)
**And** Charts show historical trend (3, 6, 12 month views)
**And** Export to PDF is available

**Given** I want regional context
**When** I view the Regional Benchmark page
**Then** My factory's metrics are compared to anonymous regional averages
**And** Ranking percentile is shown (e.g., "Top 20% in region")
**And** No competitor factory names are revealed

**Technical Notes:**
- Location: `web/factory-portal/src/pages/owner/`
- Components: ROISummary, ROIDrillDown, RegionalBenchmark
- Reference: ADR-002 for factory-portal structure

**Dependencies:**
- Story 0.5.4: Factory Portal Scaffold
- Story 3.1: Dashboard BFF Setup

**Story Points:** 5

---

#### Story 3.9: Factory Admin Settings UI

As a **Factory Administrator**,
I want to configure payment policies, grade multipliers, and SMS templates,
So that I can customize the platform for my factory's specific needs.

**Acceptance Criteria:**

**Given** I am logged in as Factory Admin
**When** I navigate to Settings → Payment Policy
**Then** I can configure price per kg by grade (Premium, Standard, Reject)
**And** I can set minimum/maximum thresholds
**And** Changes require confirmation before saving

**Given** I am on the Grade Multipliers page
**When** I configure multipliers
**Then** I can set adjustment factors for leaf type distribution
**And** Preview shows sample calculation with current settings
**And** Historical multiplier changes are logged

**Given** I am on the SMS Templates page
**When** I manage templates
**Then** I can view and edit message templates per language (EN, SW)
**And** Character count is shown with GSM-7 compatibility check
**And** Preview shows how message appears on feature phone
**And** Templates use placeholders: {farmer_name}, {grade}, {tip}

**Given** I want to understand financial impact
**When** I use the Impact Calculator
**Then** I can simulate policy changes with current data
**And** Before/after comparison shows projected farmer payouts
**And** Calculation is explained transparently

**Technical Notes:**
- Location: `web/factory-portal/src/pages/admin/`
- Components: PaymentPolicy, GradeMultipliers, SMSTemplates, ImpactCalculator
- Reference: ADR-002 for factory-portal structure

**Dependencies:**
- Story 0.5.4: Factory Portal Scaffold
- Story 3.1: Dashboard BFF Setup

**Story Points:** 5

---

#### Story 3.10: Command Center Screen Implementation

As a **Factory Quality Manager (Joseph)**,
I want the Command Center screen to show today's quality overview,
So that I can identify farmers needing intervention at a glance.

**Acceptance Criteria:**

**Given** I am logged in as Factory Manager
**When** I open the Command Center
**Then** I see today's summary: total deliveries, average grade, top issues
**And** Three sections show: "Action Needed" (red), "Watch" (amber), "Wins" (green)
**And** Farmer cards show: name, ID, grade trend, last tip sent
**And** Sorting defaults to most urgent first (lowest grade, declining trend)

**Given** I am viewing the Command Center
**When** I click on a farmer card
**Then** I navigate to Farmer Detail page
**And** Full history and action options are available

**Given** I want to take quick action
**When** I use the action strip on a farmer card
**Then** I can trigger SMS, schedule call, or mark for follow-up
**And** Action confirmation appears inline
**And** Action is logged for audit

**Given** I need temporal context
**When** I click "View Patterns"
**Then** Temporal Patterns modal shows weekly/seasonal trends
**And** Weather correlation is highlighted if significant
**And** Recommended intervention timing is suggested

**Technical Notes:**
- Location: `web/factory-portal/src/pages/manager/CommandCenter/`
- Components: FarmerCard, ActionStrip, TrendChart
- Design: "Command Center" pattern from UX spec
- Reference: `_bmad-output/ux-design-specification/`

**Dependencies:**
- Story 0.5.4: Factory Portal Scaffold
- Story 3.2: Farmer Quality Overview Grid
- Story 3.3: Farmer Categorization

**Story Points:** 5

---

#### Story 3.11: Farmer Detail Screen

As a **Factory Quality Manager**,
I want to view detailed farmer information and history,
So that I can make informed intervention decisions.

**Acceptance Criteria:**

**Given** I am on the Farmer Detail page
**When** the page loads
**Then** I see farmer profile: name, ID, farm size, collection point
**And** Contact info is shown with one-click actions (SMS, WhatsApp)
**And** Performance summary shows: avg grade, trend, total deliveries

**Given** I am viewing farmer details
**When** I look at the history section
**Then** I see a timeline of quality events (last 30 days)
**And** Each event shows: date, grade, primary %, issues detected
**And** Events can be filtered by date range

**Given** I need AI insights
**When** I view the Insights panel
**Then** I see AI-generated summary: likely cause, recommended action
**And** Weather impact correlation is shown if relevant
**And** Comparison to similar farmers in collection point

**Given** I want to send a message
**When** I click "Compose SMS"
**Then** SMSPreview component opens with farmer context pre-filled
**And** Template selection with personalization
**And** Estimated cost shown before send

**Technical Notes:**
- Location: `web/factory-portal/src/pages/manager/FarmerDetail/`
- Components: FarmerProfile, EventTimeline, InsightsPanel, SMSPreview
- API: GET /api/farmers/{id} with history

**Dependencies:**
- Story 0.5.4: Factory Portal Scaffold
- Story 3.1: Dashboard BFF Setup

**Story Points:** 5

---

#### Story 3.12: SMS Preview and Compose

As a **Factory Quality Manager**,
I want to preview and compose SMS messages to farmers,
So that I can communicate effectively with proper personalization.

**Acceptance Criteria:**

**Given** I open the SMS Compose dialog
**When** I select a template
**Then** Template is populated with farmer context (name, grade, tip)
**And** Preview shows exactly how message appears on phone
**And** Character count shows: current/160 or current/320

**Given** I am composing a message
**When** I exceed 160 characters
**Then** Warning shows: "Message will be split (2 SMS, higher cost)"
**And** Character count turns amber
**And** Non-GSM-7 characters are highlighted for replacement

**Given** the message is ready
**When** I click "Send"
**Then** Confirmation dialog shows: recipient, message, estimated cost
**And** After confirmation, message is queued for delivery
**And** Success notification shows: "SMS queued - delivery in ~30 seconds"

**Given** I want to send to multiple farmers
**When** I select multiple farmers from Command Center
**Then** Bulk SMS option appears in action bar
**And** Same template is applied to all with individual personalization
**And** Total cost estimate shown before confirmation

**Technical Notes:**
- Component: `@fp/ui-components/SMSPreview`
- GSM-7 validation in component
- API: POST /api/sms/send (single), POST /api/sms/bulk (multiple)
- Integration with Story 4.1: Notification Model

**Dependencies:**
- Story 0.5.1: Shared Component Library
- Story 3.1: Dashboard BFF Setup

**Story Points:** 3

---

### Epic 4: Farmer SMS Feedback

#### Story 4.1: Notification Model Service Setup

As a **platform operator**,
I want the Notification Model service deployed with SMS gateway integration,
So that farmers can receive SMS notifications about their quality results.

**Acceptance Criteria:**

**Given** the Kubernetes cluster is running with Dapr installed
**When** the Notification Model service is deployed
**Then** the service starts successfully with health check endpoint returning 200
**And** the Dapr sidecar is injected and connected
**And** MongoDB connection is established for delivery tracking
**And** gRPC server is listening on port 50053
**And** OpenTelemetry traces are emitted for all operations

**Given** the service is running
**When** the Africa's Talking SMS gateway is configured
**Then** API credentials are loaded from Azure Key Vault
**And** the gateway connection is verified via test message
**And** shortcode is configured (e.g., 22384)

**Given** the service is running
**When** subscribed to Dapr pub/sub topics
**Then** "collection.end_bag.received" events trigger SMS generation
**And** "action_plan.generated" events trigger weekly SMS delivery

**Given** the service receives a send request
**When** processing begins
**Then** farmer preferences are fetched from Plantation Model
**And** message is translated to farmer's pref_lang
**And** delivery attempt is logged with timestamp

**Technical Notes:**
- Python FastAPI + grpcio
- Africa's Talking SDK for Kenya SMS
- Azure Key Vault for API credentials
- Environment: farmer-power-{env} namespace

---

#### Story 4.2: SMS Message Generation

As a **farmer**,
I want to receive SMS feedback in my local language with my quality results,
So that I understand how my tea performed and what to improve.

**Acceptance Criteria:**

**Given** a quality event is processed for a farmer
**When** SMS generation is triggered (within 3 hours)
**Then** an SMS is generated with: farmer_name, grade (star rating ★★★), primary_percentage, ONE actionable tip

**Given** the farmer's pref_lang is "sw" (Swahili)
**When** the SMS is generated
**Then** the message is in Swahili
**And** the message uses culturally appropriate phrasing

**Given** the farmer's pref_lang is "ki" (Kikuyu) or "luo" (Luo)
**When** the SMS is generated
**Then** the message is in the respective language
**And** translation quality is verified against approved templates

**Given** the SMS must show price impact
**When** the grade affects payment
**Then** the message includes: "This grade means KES {amount} per kg" or similar
**And** the amount is calculated based on factory price tiers

**Given** the farmer has an improving trajectory (last 3 deliveries trending up)
**When** the SMS is generated
**Then** a personalized encouragement is included: "{name}, you're improving! 📈"

**Given** the SMS content exceeds 160 characters
**When** using GSM-7 encoding
**Then** the message is trimmed to fit single SMS (160 chars)
**And** the actionable tip is prioritized over additional context

**Given** the SMS contains non-GSM-7 characters
**When** encoding is checked
**Then** the message falls back to UCS-2 encoding (70 chars)
**And** content is further condensed to fit

**Technical Notes:**
- Message templates stored in MongoDB (versioned)
- Translation via pre-approved templates (not real-time LLM)
- GSM-7 character validation before send
- Star rating: Grade 1 = ★★★, Grade 2 = ★★, Grade 3 = ★

---

#### Story 4.3: SMS Cost Optimization

As a **platform operator**,
I want SMS costs minimized while maintaining message effectiveness,
So that per-farmer costs stay under $0.50/year target.

**Acceptance Criteria:**

**Given** an SMS is being composed
**When** the message fits in 160 GSM-7 characters
**Then** it is sent as a single SMS (1 segment)
**And** the cost is 1 SMS credit

**Given** an SMS is being composed
**When** the message requires 161-320 GSM-7 characters
**Then** a warning is logged for review
**And** the system attempts to condense the message
**And** if condensing fails, it sends as 2-segment SMS

**Given** the farmer has no quality issues (Grade 1)
**When** deciding whether to send SMS
**Then** the SMS is sent with celebration message (shorter)
**And** premium farmers may opt out of "good news" SMS

**Given** a batch of SMS needs to be sent (e.g., 1000 farmers)
**When** the batch is processed
**Then** messages are queued and rate-limited (10 SMS/second)
**And** gateway rate limits are respected
**And** total batch cost is logged for monitoring

**Given** SMS cost metrics are collected
**When** viewing the admin dashboard
**Then** cost per factory, cost per farmer, SMS segment distribution are visible
**And** alerts trigger if cost exceeds $0.50/farmer/year

**Technical Notes:**
- Africa's Talking pricing: ~KES 0.8/SMS (~$0.006)
- Target: <100 SMS/farmer/year = $0.60/year
- Batch processing via Azure Service Bus
- Cost tracking in MongoDB: sms_costs collection

---

#### Story 4.4: SMS Delivery Assurance

As a **platform operator**,
I want SMS delivery tracked with retry logic,
So that critical messages reach farmers reliably.

**Acceptance Criteria:**

**Given** an SMS is sent to a farmer
**When** the gateway returns delivery status
**Then** the status is stored: sent, delivered, failed, pending
**And** the delivery_report webhook updates the status

**Given** an SMS fails to deliver (network error)
**When** retry logic is triggered
**Then** the message is retried up to 3 times for standard messages
**And** retry intervals: 5 min, 30 min, 2 hours
**And** each retry attempt is logged

**Given** an SMS is marked as "critical" (e.g., Grade 3 urgent issue)
**When** delivery fails
**Then** the message is retried up to 6 times
**And** retry intervals: 5 min, 15 min, 1 hour, 4 hours, 12 hours, 24 hours

**Given** all retry attempts fail
**When** the message is exhausted
**Then** the status is set to "undeliverable"
**And** lead farmer escalation is triggered (see Story 4.5)
**And** an alert is logged for factory manager visibility

**Given** the farmer's phone is turned off
**When** the gateway reports "phone unreachable"
**Then** the system waits and retries during typical active hours (6 AM - 8 PM local)

**Given** delivery tracking data exists
**When** querying farmer SMS history
**Then** all attempts, statuses, and timestamps are returned
**And** delivery rate metrics are aggregated for reporting

**Technical Notes:**
- Africa's Talking delivery reports via webhook
- Retry queue: Azure Service Bus with delay scheduling
- Delivery status: sent → pending → delivered | failed | undeliverable
- Critical flag set by Grade 3 or declining streak

---

#### Story 4.5: Lead Farmer Escalation

As a **factory quality manager**,
I want unreachable farmers escalated to lead farmers,
So that critical quality messages still reach the farmer through community networks.

**Acceptance Criteria:**

**Given** a farmer cannot be reached after all retry attempts
**When** escalation is triggered
**Then** the system identifies the farmer's lead farmer (from Plantation Model)
**And** an SMS is sent to the lead farmer

**Given** a lead farmer receives an escalation SMS
**When** the message is composed
**Then** it includes: target farmer name, collection point, brief issue summary, request to relay message
**And** the message respects the lead farmer's language preference

**Given** a lead farmer is assigned to multiple farmers
**When** multiple escalations occur within 1 hour
**Then** messages are aggregated: "3 farmers in your group need attention: {names}"
**And** a single SMS is sent with combined information

**Given** the lead farmer is also unreachable
**When** all escalation attempts fail
**Then** the issue is flagged for factory manager review
**And** appears in the dashboard "Unreachable Farmers" section

**Given** the target farmer is eventually reached (phone back on)
**When** they receive the original message
**Then** the escalation is marked as resolved
**And** the lead farmer receives optional confirmation: "{farmer_name} received their message"

**Technical Notes:**
- Lead farmer relationship in Plantation Model
- Aggregation window: 1 hour
- Lead farmer SMS priority: standard (3 retries)
- Dashboard flag in Collection Model events

---

#### Story 4.6: Inbound Keyword Handling

As a **farmer**,
I want to reply to SMS with keywords to get help or update my status,
So that I can interact with the system even without data/internet.

**Acceptance Criteria:**

**Given** a farmer replies with "HELP" (or "MSAADA" in Swahili)
**When** the message is received
**Then** an auto-reply is sent: brief help menu with available keywords
**And** the message is in the farmer's preferred language

**Given** a farmer replies with "DONE" (or "IMEFANYIKA")
**When** the message is received
**Then** the current week's action plan is marked as acknowledged
**And** a confirmation reply is sent: "Great! We'll check your next delivery."

**Given** a farmer replies with "STOP" (or "SIMAMA")
**When** the message is received
**Then** the farmer is opted out of non-critical SMS
**And** only Grade 3 critical alerts are still sent
**And** a confirmation reply is sent with opt-back-in instructions

**Given** a farmer replies with "STATUS" (or "HALI")
**When** the message is received
**Then** a reply is sent with: current grade, last delivery date, trend
**And** the message fits in a single SMS

**Given** a farmer replies with an unrecognized keyword
**When** the message is received
**Then** an auto-reply is sent: "We didn't understand. Reply HELP for options."
**And** the unknown message is logged for review (potential new keyword discovery)

**Given** inbound messages are received
**When** processing
**Then** farmer is identified by phone number (lookup in Plantation Model)
**And** message is logged with timestamp and response

**Technical Notes:**
- Africa's Talking inbound webhook
- Keyword matching: case-insensitive, language-aware aliases
- Farmer lookup: phone → farmer_id
- Logging: inbound_messages collection

---

#### Story 4.7: Group and Regional Messaging

As a **factory quality manager**,
I want to send SMS to groups of farmers or entire regions,
So that I can communicate important announcements efficiently.

**Acceptance Criteria:**

**Given** I am a factory manager in the dashboard
**When** I compose a regional broadcast message
**Then** I can select: all farmers, specific collection points, specific grades, or custom filter
**And** the recipient count is shown before sending

**Given** I compose a broadcast message
**When** I enter the message text
**Then** the SMSPreview component shows character count and segment count
**And** translations are previewed for each language (Swahili, Kikuyu, Luo, English)

**Given** I send a broadcast to 1000+ farmers
**When** the send is triggered
**Then** messages are queued in batches (100 per batch)
**And** progress is shown: "Sending... 450/1000"
**And** rate limiting is enforced (10 SMS/second)

**Given** a broadcast is sent
**When** delivery completes
**Then** a summary report is generated: sent count, delivered count, failed count, cost
**And** the report is available in the Reports section

**Given** a broadcast message is scheduled (not immediate)
**When** the scheduled time arrives
**Then** the broadcast is sent automatically
**And** the factory manager receives confirmation notification

**Given** a broadcast is in progress
**When** the factory manager clicks "Cancel"
**Then** remaining unsent messages are cancelled
**And** already-sent messages remain (cannot be recalled)
**And** a partial delivery report is generated

**Technical Notes:**
- Broadcast queue: Azure Service Bus with priority
- Scheduling: Dapr Jobs component
- Rate limit: configurable per factory
- Cost estimate shown before send: "~KES {amount}"

---

### Epic 5: Quality Diagnosis AI

#### Story 5.1: Knowledge Model Service Setup

As a **platform operator**,
I want the Knowledge Model service deployed with LangGraph and RAG capabilities,
So that quality issues can be automatically diagnosed.

**Acceptance Criteria:**

**Given** the Kubernetes cluster is running with Dapr installed
**When** the Knowledge Model service is deployed
**Then** the service starts successfully with health check endpoint returning 200
**And** the Dapr sidecar is injected and connected
**And** MongoDB connection is established for Analysis DB
**And** Pinecone connection is established for Vector DB
**And** OpenTelemetry traces are emitted for all operations

**Given** the service is running
**When** subscribed to Dapr pub/sub
**Then** "collection.poor_quality_detected" events trigger triage workflow
**And** scheduled jobs trigger weekly trend analysis

**Given** the service processes a diagnosis request
**When** LangGraph workflow executes
**Then** workflow state is persisted to MongoDB
**And** all LLM calls are traced via LangChain callbacks
**And** RAG queries are logged with retrieved chunks

**Given** the LLM API is unavailable
**When** a diagnosis is requested
**Then** the request is queued for retry (exponential backoff)
**And** an alert is logged for monitoring
**And** previous diagnoses remain unaffected

**Technical Notes:**
- Python with LangChain/LangGraph
- Claude Haiku for triage, Claude Sonnet for specialized analysis
- Pinecone: farmer-power-knowledge index
- Environment: farmer-power-{env} namespace

---

#### Story 5.2: Event Aggregation Engine

As a **Knowledge Model system**,
I want to aggregate quality events before analysis,
So that diagnoses have more evidence and LLM costs are reduced.

**Acceptance Criteria:**

**Given** a "collection.poor_quality_detected" event is received
**When** the farmer has no pending events in the aggregation window
**Then** a new aggregation bucket is created with 24-hour TTL
**And** the event is added to the bucket
**And** a delayed analysis trigger is scheduled (30 minutes)

**Given** additional events arrive for the same farmer within 24 hours
**When** the aggregation bucket exists
**Then** events are added to the existing bucket
**And** the analysis trigger is reset (30-minute delay from latest event)
**And** a maximum of 10 events are held before forced analysis

**Given** the aggregation window expires (30 min of no new events)
**When** the analysis is triggered
**Then** all events in the bucket are passed to the Triage Agent
**And** the diagnosis references all source event_ids
**And** the bucket is cleared

**Given** a critical priority event is detected (primary_percentage < 40%)
**When** the event arrives
**Then** aggregation is bypassed
**And** immediate analysis is triggered
**And** existing bucket events are included in the analysis

**Given** the aggregation engine fails
**When** events cannot be bucketed
**Then** events are processed individually (fallback)
**And** an alert is logged
**And** no events are lost

**Technical Notes:**
- Aggregation state: Redis with TTL
- Bucket key: farmer_id
- Scheduled triggers: Dapr Jobs
- Critical threshold: configurable per factory

---

#### Story 5.3: Triage Agent

As a **Knowledge Model system**,
I want a Triage Agent to classify quality issues and route to specialists,
So that the right analyzer processes each issue efficiently.

**Acceptance Criteria:**

**Given** aggregated quality events are ready for analysis
**When** the Triage Agent receives them
**Then** it classifies the probable cause: disease, weather, technique, trend, unknown
**And** confidence score (0.0-1.0) is assigned to the classification
**And** the classification and confidence are logged

**Given** the Triage Agent classifies with confidence ≥ 0.7
**When** routing decision is made
**Then** events are routed to the single most likely analyzer
**And** the routing path is recorded in the workflow state

**Given** the Triage Agent classifies with confidence < 0.7
**When** routing decision is made
**Then** events are routed to multiple analyzers in parallel
**And** results are merged after all analyzers complete
**And** the parallel execution is logged

**Given** the Triage Agent cannot classify (unknown)
**When** confidence is below 0.3
**Then** the event is flagged for human review
**And** a "diagnosis.needs_review" event is published
**And** partial analysis is still attempted with all analyzers

**Given** the Triage Agent runs
**When** processing completes
**Then** LLM usage (tokens, model, latency) is logged
**And** triage accuracy metrics are collected for feedback loop

**Technical Notes:**
- LLM: Claude Haiku (fast, cheap)
- Prompt: few-shot examples from validated diagnoses
- Parallel routing: LangGraph conditional edges
- Max latency target: 2 seconds

---

#### Story 5.4: Disease Detection Agent

As a **Knowledge Model system**,
I want a Disease Detection Agent to identify plant diseases from images,
So that disease-related quality issues are accurately diagnosed.

**Acceptance Criteria:**

**Given** quality events are routed to Disease Detection
**When** events include image references
**Then** images are fetched from Azure Blob Storage
**And** images are analyzed using vision-capable LLM
**And** visual symptoms are described in natural language

**Given** images are analyzed
**When** disease symptoms are detected
**Then** the diagnosis includes: disease_name, confidence, affected_area, severity
**And** RAG is queried for disease identification and treatment guidance
**And** the diagnosis references the expert knowledge source

**Given** RAG provides disease knowledge
**When** the diagnosis is generated
**Then** the response includes: identified_condition, confidence, severity, details
**And** details explain what symptoms were observed
**And** NO treatment recommendations are provided (that's Action Plan's job)

**Given** no disease is detected
**When** the analysis completes
**Then** the diagnosis indicates: condition="none_detected", confidence=high
**And** the agent suggests alternative causes (weather, technique)

**Given** image quality is poor (blurry, too dark)
**When** analysis is attempted
**Then** the diagnosis indicates: image_quality="insufficient"
**And** confidence is lowered appropriately
**And** a note is added requesting better images in future

**Technical Notes:**
- LLM: Claude Sonnet (vision capability)
- Image preprocessing: resize to max 1024px
- RAG domain: plant_diseases
- Max images per analysis: 10

---

#### Story 5.5: Weather Impact Analyzer

As a **Knowledge Model system**,
I want a Weather Impact Analyzer to correlate weather with quality issues,
So that weather-related causes are identified with appropriate lag.

**Acceptance Criteria:**

**Given** quality events are routed to Weather Impact Analyzer
**When** processing begins
**Then** weather data for the farmer's region is fetched (past 14 days)
**And** the 3-7 day lag window is applied per weather event type

**Given** weather data shows heavy rain (>50mm/day) 3-5 days before delivery
**When** correlation is analyzed
**Then** the diagnosis includes: condition="moisture_excess", weather_event="heavy_rain", lag_days=X
**And** confidence is weighted by rainfall amount and timing

**Given** weather data shows frost (<2°C) 3-5 days before delivery
**When** correlation is analyzed
**Then** the diagnosis includes: condition="frost_damage", weather_event="frost", lag_days=X
**And** RAG is queried for frost impact on tea quality

**Given** weather data shows drought (>5 days no rain) 4-7 days before
**When** correlation is analyzed
**Then** the diagnosis includes: condition="moisture_deficit", weather_event="drought", lag_days=X

**Given** weather data shows high humidity (>90%) 2-4 days before
**When** correlation is analyzed
**Then** the diagnosis includes: condition="fungal_risk", weather_event="high_humidity"
**And** Disease Detection is triggered as secondary analyzer

**Given** no weather correlation is found
**When** analysis completes
**Then** the diagnosis indicates: weather_impact="none_detected"
**And** the agent suggests alternative causes

**Technical Notes:**
- Weather data: from Collection Model (pull mode)
- Lag weights: configurable per event type
- Seasonal adjustments: dry season vs rainy season
- LLM: Claude Haiku (text analysis)

---

#### Story 5.6: Technique Assessment Agent

As a **Knowledge Model system**,
I want a Technique Assessment Agent to identify harvesting/handling problems,
So that technique-related quality issues are diagnosed.

**Acceptance Criteria:**

**Given** quality events are routed to Technique Assessment
**When** processing begins
**Then** leaf_type_distribution is analyzed for technique indicators
**And** historical patterns for this farmer are fetched

**Given** leaf assessments show high coarse_leaf percentage (>30%)
**When** analysis is performed
**Then** the diagnosis includes: condition="over_plucking", indicator="high_coarse_leaf"
**And** RAG is queried for proper plucking technique guidance

**Given** leaf assessments show high banji percentage (>20%)
**When** analysis is performed
**Then** the diagnosis includes: condition="poor_timing", indicator="high_banji"
**And** banji_hardness distribution is analyzed (soft vs hard)

**Given** leaf assessments show high damaged leaves
**When** damage_percentage > 15%
**Then** the diagnosis includes: condition="handling_damage", indicator="damaged_leaves"
**And** RAG suggests handling improvements

**Given** farmer's technique has been consistent but quality dropped
**When** historical comparison shows sudden change
**Then** the diagnosis notes: "technique_consistent, other_factors_likely"
**And** confidence in technique as cause is lowered

**Given** multiple technique issues are detected
**When** generating diagnosis
**Then** issues are prioritized by severity
**And** the primary issue is highlighted with supporting details

**Technical Notes:**
- LLM: Claude Haiku
- RAG domain: harvesting_techniques
- Historical window: 30 days
- Thresholds configurable per region

---

#### Story 5.7: Trend Analysis Agent

As a **Knowledge Model system**,
I want a Trend Analysis Agent to detect patterns over time,
So that recurring or seasonal issues are identified proactively.

**Acceptance Criteria:**

**Given** the weekly trend analysis job runs (Sunday midnight)
**When** farmers with ≥5 deliveries in past 30 days are identified
**Then** trend analysis is triggered for each qualifying farmer

**Given** a farmer's quality is analyzed for trends
**When** the analysis runs
**Then** primary_percentage trend is calculated (improving, stable, declining)
**And** seasonal patterns are identified (wet season vs dry season)
**And** comparison to regional average is computed

**Given** a declining trend is detected (>10% drop over 4 weeks)
**When** the diagnosis is generated
**Then** the diagnosis includes: condition="quality_decline", trend_direction="declining", decline_rate="X%/week"
**And** a "diagnosis.trend_alert" event is published

**Given** a farmer is performing below regional average
**When** the percentile is calculated
**Then** yield_percentile is stored (e.g., "25th percentile")
**And** the diagnosis notes performance relative to peers

**Given** a seasonal pattern is detected
**When** current period matches historical low
**Then** the diagnosis includes: condition="seasonal_pattern", historical_context="dry_season_typical"
**And** this context is passed to Action Plan Model

**Given** no significant trends are detected
**When** the farmer has stable quality
**Then** a positive trend record is created: condition="stable_performance"
**And** no alert is published

**Technical Notes:**
- Schedule: Dapr Jobs (Sunday 00:00)
- Statistical analysis: Python pandas
- No LLM required for basic trend calculation
- LLM used for pattern interpretation and context

---

#### Story 5.8: RAG Knowledge Base

As a **platform operator**,
I want a curated knowledge base for RAG enrichment,
So that diagnoses are informed by expert agricultural knowledge.

**Acceptance Criteria:**

**Given** the Pinecone vector database is configured
**When** the knowledge base is initialized
**Then** the following domains are indexed: plant_diseases, tea_cultivation, weather_patterns, harvesting_techniques

**Given** an agronomist uploads new knowledge content
**When** content is processed
**Then** text is chunked (500 tokens with 100 token overlap)
**And** embeddings are generated (OpenAI ada-002)
**And** chunks are stored in Pinecone with metadata: domain, source, version, date

**Given** an agent queries the knowledge base
**When** a RAG search is performed
**Then** top 5 most relevant chunks are returned
**And** relevance scores are included
**And** source citations are preserved for attribution

**Given** knowledge content is versioned
**When** a new version is uploaded
**Then** the old version is retained (soft delete)
**And** agents use the latest version by default
**And** A/B testing can compare versions

**Given** a query returns low-relevance results (score < 0.7)
**When** the agent processes results
**Then** the agent is notified of low confidence
**And** the agent can proceed without RAG or flag for review

**Given** Pinecone is unavailable
**When** a RAG query is attempted
**Then** the query fails gracefully
**And** the agent proceeds without RAG enrichment (degraded mode)
**And** an alert is logged

**Technical Notes:**
- Pinecone: farmer-power-knowledge index
- Embedding model: text-embedding-ada-002
- Namespace per domain for isolated queries
- Knowledge curated by agronomists (not auto-generated)

---

#### Story 5.9: Knowledge Model MCP Server

As an **AI agent (Action Plan Model)**,
I want to access diagnoses via MCP tools,
So that action plans can be generated based on analysis results.

**Acceptance Criteria:**

**Given** the Knowledge MCP Server is deployed
**When** an AI agent calls `get_farmer_analyses(farmer_id, date_range, type?)`
**Then** all matching diagnoses are returned
**And** each diagnosis includes: type, condition, confidence, severity, details, source_documents

**Given** an analysis_id exists
**When** an AI agent calls `get_analysis_by_id(analysis_id)`
**Then** the full diagnosis is returned including RAG context used

**Given** the Action Plan Model needs recent diagnoses
**When** an AI agent calls `get_recent_diagnoses(farmer_id, since_date)`
**Then** diagnoses created since the specified date are returned
**And** results are sorted by severity (critical first)

**Given** a search query is needed
**When** an AI agent calls `search_analyses(query, filters, limit)`
**Then** text search is performed across diagnosis details
**And** filters can include: farmer_id, type, severity, date_range
**And** results are ranked by relevance

**Given** trend data is needed
**When** an AI agent calls `get_farmer_trend(farmer_id)`
**Then** the latest trend analysis is returned
**And** includes: trend_direction, percentile, seasonal_context

**Given** the MCP Server receives a request
**When** processing completes
**Then** OpenTelemetry traces are emitted
**And** tool usage is logged for cost attribution

**Technical Notes:**
- MCP Server deployed as separate Kubernetes deployment
- HPA enabled: min 2, max 10 replicas
- Read-only access to Analysis DB (MongoDB)
- gRPC interface following MCP protocol

---

### Epic 6: Weekly Action Plans

#### Story 6.1: Action Plan Model Service Setup

As a **platform operator**,
I want the Action Plan Model service deployed with scheduled generation capability,
So that farmers receive weekly personalized improvement recommendations.

**Acceptance Criteria:**

**Given** the Kubernetes cluster is running with Dapr installed
**When** the Action Plan Model service is deployed
**Then** the service starts successfully with health check endpoint returning 200
**And** the Dapr sidecar is injected and connected
**And** MongoDB connection is established for Action Plan DB
**And** MCP client connections to Knowledge, Plantation, Collection Models are configured
**And** OpenTelemetry traces are emitted for all operations

**Given** the service is running
**When** the Monday 6 AM scheduled job is configured
**Then** Dapr Jobs component triggers action plan generation weekly
**And** the schedule is per-factory timezone (Africa/Nairobi)

**Given** the service needs to generate action plans
**When** MCP tools are invoked
**Then** `get_farmer_analyses`, `get_farmer_summary`, `get_recent_quality_events` are available
**And** all tool calls are traced and logged

**Given** the LLM API is unavailable during generation
**When** the scheduled job runs
**Then** failed farmers are queued for retry (1 hour later)
**And** successful generations proceed
**And** partial success is logged with failure count

**Technical Notes:**
- Python with LangChain/LangGraph
- Claude Sonnet for action plan generation
- Schedule: Monday 06:00 Africa/Nairobi
- Environment: farmer-power-{env} namespace

---

#### Story 6.2: Weekly Action Plan Generation

As a **farmer**,
I want to receive a weekly action plan based on my recent quality data,
So that I know what specific steps to take to improve my tea quality.

**Acceptance Criteria:**

**Given** the Monday 6 AM generation job runs
**When** farmers with deliveries in the past 7 days are identified
**Then** action plan generation is triggered for each farmer
**And** farmers are processed in batches (100 per batch)
**And** rate limiting is applied to LLM calls (10/second)

**Given** a farmer has diagnoses from Knowledge Model
**When** the action plan is generated
**Then** the AI queries `get_farmer_analyses(farmer_id, past_7_days)`
**And** diagnoses are prioritized by severity
**And** the top 3 issues are selected for recommendations

**Given** diagnoses are retrieved
**When** recommendations are generated
**Then** each recommendation includes: issue (what's wrong), action (what to do), why (expected impact)
**And** actions are specific and actionable (not generic advice)
**And** actions reference the specific diagnosis details

**Given** a farmer has no quality issues (all Grade 1)
**When** the action plan is generated
**Then** a celebration message is created: "Great work this week! Keep up the excellent quality."
**And** optional tip for maintaining quality is included
**And** encouragement to help neighbors is suggested

**Given** action plan generation completes
**When** the plan is stored
**Then** it includes: farmer_id, week_number, diagnoses_referenced, recommendations[], generated_at
**And** an "action_plan.generated" event is published for Notification Model
**And** the plan is marked as "pending_delivery"

**Technical Notes:**
- LLM: Claude Sonnet
- Max 3 recommendations per plan
- RAG enrichment from Knowledge Base (cultivation tips)
- Generation timeout: 30 seconds per farmer

---

#### Story 6.3: Farm-Scale-Aware Recommendations

As a **farmer with a specific farm size**,
I want recommendations tailored to my scale of operation,
So that advice is practical for my situation.

**Acceptance Criteria:**

**Given** a farmer's farm_scale is "smallholder" (<1 hectare)
**When** recommendations are generated
**Then** advice focuses on: manual techniques, low-cost solutions, family labor optimization
**And** language is simple and jargon-free
**And** equipment recommendations avoid expensive purchases

**Given** a farmer's farm_scale is "medium" (1-5 hectares)
**When** recommendations are generated
**Then** advice includes: basic tool investments, hired labor coordination, batch processing techniques
**And** cost-benefit analysis is provided for larger investments

**Given** a farmer's farm_scale is "estate" (>5 hectares)
**When** recommendations are generated
**Then** advice includes: workforce management, equipment investments, process optimization
**And** recommendations may reference management practices
**And** ROI calculations are included for capital investments

**Given** farm_scale context is passed to LLM
**When** the prompt is constructed
**Then** few-shot examples appropriate for that scale are included
**And** the system prompt emphasizes scale-appropriate advice

**Given** yield_vs_regional_avg is below average
**When** recommendations are generated
**Then** the plan includes specific catch-up strategies
**And** comparison to successful peers at similar scale is referenced

**Technical Notes:**
- farm_scale from Plantation Model
- Few-shot examples per scale category
- yield_vs_regional_avg from Plantation Model summary
- Prompt template versioned for A/B testing

---

#### Story 6.4: Dual-Format Output (Report + SMS)

As a **farmer**,
I want to receive both a detailed report and a short SMS summary,
So that I can get quick tips via SMS and refer to details later.

**Acceptance Criteria:**

**Given** an action plan is generated
**When** the detailed report is created
**Then** it includes: header (farmer name, week), issues section (list of diagnoses), recommendations section (numbered steps), next steps
**And** the report is stored in Action Plan DB
**And** the report is 300-500 words

**Given** an action plan is generated
**When** the SMS summary is created
**Then** it condenses the plan to: grade stars, ONE priority action, encouragement phrase
**And** the SMS is under 160 GSM-7 characters
**And** the SMS ends with "Call *384# for full plan"

**Given** the SMS summary is created
**When** passed to Notification Model
**Then** the `action_plan.generated` event includes: farmer_id, sms_content, detailed_report_id
**And** the Notification Model handles delivery

**Given** a farmer calls Voice IVR for details
**When** they request their action plan
**Then** the full detailed report is converted to TTS script
**And** the TTS script is structured for audio delivery (pauses, emphasis)

**Given** the detailed report is too long for TTS (>3 min)
**When** the TTS script is generated
**Then** the script is summarized to fit 2-3 minute audio
**And** the full report remains available in the system

**Technical Notes:**
- LLM generates both formats in single call
- SMS format strict: 160 char limit enforced
- TTS script: SSML-compatible formatting
- Storage: action_plans collection with reports and sms_summaries

---

#### Story 6.5: Multilingual Translation

As a **farmer**,
I want my action plan in my preferred language,
So that I fully understand the recommendations.

**Acceptance Criteria:**

**Given** a farmer's pref_lang is "sw" (Swahili)
**When** the action plan is generated
**Then** both detailed report and SMS are in Swahili
**And** agricultural terms use locally understood vocabulary
**And** the language is natural, not machine-translated sounding

**Given** a farmer's pref_lang is "ki" (Kikuyu)
**When** the action plan is generated
**Then** the content is translated to Kikuyu
**And** cultural context is preserved (e.g., local farming practices)

**Given** a farmer's pref_lang is "luo" (Luo)
**When** the action plan is generated
**Then** the content is translated to Luo
**And** regional farming terminology is used

**Given** translation is needed
**When** the LLM generates the action plan
**Then** the prompt includes language instruction
**And** few-shot examples in the target language guide output
**And** fallback to English is available if translation quality is poor

**Given** a translation quality check fails
**When** the output is validated
**Then** the plan is flagged for human review
**And** English version is delivered as fallback
**And** a "translation.quality_issue" event is logged

**Technical Notes:**
- LLM generates in target language directly (not post-translation)
- Few-shot examples in Swahili, Kikuyu, Luo pre-validated by native speakers
- Quality check: basic grammar/coherence validation
- Fallback flag: use_english_fallback

---

#### Story 6.6: Action Plan MCP Server

As an **AI agent (Conversational AI)**,
I want to access action plans via MCP tools,
So that Voice Quality Advisor can reference farmer's current recommendations.

**Acceptance Criteria:**

**Given** the Action Plan MCP Server is deployed
**When** an AI agent calls `get_current_action_plan(farmer_id)`
**Then** the most recent action plan is returned
**And** includes: week_number, recommendations[], status (pending/delivered/acknowledged)

**Given** a farmer_id exists
**When** an AI agent calls `get_action_plan_history(farmer_id, weeks=4)`
**Then** action plans from the past 4 weeks are returned
**And** results show progression and recurring themes

**Given** a specific recommendation needs context
**When** an AI agent calls `get_recommendation_details(plan_id, rec_index)`
**Then** the full diagnosis chain is returned
**And** includes: original quality event, diagnosis, RAG context used, recommendation reasoning

**Given** the Conversational AI needs to explain a recommendation
**When** it queries the action plan
**Then** sufficient context is available for natural explanation
**And** the farmer's history informs the response

**Given** no action plan exists for current week
**When** `get_current_action_plan` is called
**Then** the response indicates: "no_plan_this_week"
**And** the previous week's plan is optionally returned

**Given** the MCP Server receives a request
**When** processing completes
**Then** OpenTelemetry traces are emitted
**And** tool usage is logged for cost attribution

**Technical Notes:**
- MCP Server deployed as separate Kubernetes deployment
- HPA enabled: min 2, max 10 replicas
- Read-only access to Action Plan DB
- gRPC interface following MCP protocol

---

### Epic 7: Voice IVR Experience

#### Story 7.1: Voice IVR Service Setup

As a **platform operator**,
I want the Voice IVR service deployed with telephony integration,
So that farmers can call and hear their action plans.

**Acceptance Criteria:**

**Given** the Kubernetes cluster is running
**When** the Voice IVR service is deployed
**Then** the service starts successfully with health check endpoint returning 200
**And** Africa's Talking Voice API is configured
**And** shortcode (*384#) is registered and active
**And** OpenTelemetry traces are emitted for all calls

**Given** the service is running
**When** a call is received on the shortcode
**Then** the incoming call webhook is triggered
**And** call session is created with unique call_id
**And** call start time is logged

**Given** Voice IVR needs TTS capability
**When** the service initializes
**Then** Google Cloud TTS is configured
**And** voice models for Swahili, English are loaded
**And** fallback to Africa's Talking TTS is available

**Given** a call is in progress
**When** the call ends (hangup, timeout, error)
**Then** call duration is logged
**And** call outcome is recorded (completed, abandoned, error)
**And** metrics are collected for reporting

**Technical Notes:**
- Python FastAPI with async support
- Africa's Talking Voice API for telephony
- Google Cloud TTS: Swahili (sw-KE), Kikuyu (Wavenet), English (en-KE)
- Shortcode: *384# (USSD-style for Kenya)
- Environment: farmer-power-{env} namespace

---

#### Story 7.2: Caller ID Farmer Identification

As a **farmer**,
I want to be automatically identified when I call,
So that I can hear my personalized action plan without entering my ID.

**Acceptance Criteria:**

**Given** a farmer calls the Voice IVR shortcode
**When** the call is received
**Then** the caller's phone number is extracted
**And** Plantation Model is queried: `get_farmer_by_phone(phone)`

**Given** the phone number matches a registered farmer
**When** lookup succeeds
**Then** the farmer's name, pref_lang, and farmer_id are retrieved
**And** a greeting plays: "Jambo {farmer_name}, karibu!"
**And** the call proceeds to language selection

**Given** the phone number is not registered
**When** lookup fails
**Then** a prompt plays: "We don't recognize this number. Please enter your farmer ID."
**And** DTMF input is collected (farmer_id digits)
**And** the entered ID is validated against Plantation Model

**Given** the farmer enters an invalid farmer_id
**When** validation fails
**Then** an error message plays: "That ID was not found. Please try again."
**And** the farmer can retry up to 3 times
**And** after 3 failures, the call offers "Press 0 for help"

**Given** a farmer is identified (by phone or ID)
**When** identification completes
**Then** the farmer_id is stored in call session
**And** all subsequent actions use this farmer context

**Technical Notes:**
- Caller ID: E.164 format (+254...)
- DTMF timeout: 10 seconds
- Farmer ID format: WM-XXXX (4 digits)
- Session storage: Redis with call_id key

---

#### Story 7.3: Language Selection Menu

As a **farmer**,
I want to choose my language when calling,
So that I hear the action plan in a language I understand.

**Acceptance Criteria:**

**Given** a farmer is identified
**When** language selection begins
**Then** a menu plays: "For Swahili, press 1. For Kikuyu, press 2. For Luo, press 3. For English, press 4."
**And** each option is read in the respective language

**Given** the farmer's pref_lang is already set
**When** the menu plays
**Then** the farmer's preferred language is suggested: "Press 1 for Swahili (your usual language)"
**And** the preferred option is listed first

**Given** a farmer selects a language option
**When** DTMF input is received
**Then** the selected language is stored in call session
**And** all subsequent audio is in the selected language
**And** "Asante" (or equivalent) confirmation plays

**Given** no input is received within 10 seconds
**When** the timeout occurs
**Then** the menu replays once
**And** if still no input after second play, default to pref_lang
**And** proceed with action plan playback

**Given** an invalid key is pressed
**When** input is received
**Then** "Sorry, that option is not available. Let's try again." plays
**And** the menu replays

**Technical Notes:**
- Languages: sw (Swahili), ki (Kikuyu), luo (Luo), en (English)
- DTMF: 1=sw, 2=ki, 3=luo, 4=en, 0=help
- TTS voices: Google Cloud Wavenet where available
- Kikuyu/Luo: may use pre-recorded audio (TTS limited)

---

#### Story 7.4: Action Plan TTS Playback

As a **farmer**,
I want to hear my weekly action plan read aloud,
So that I understand my recommendations without needing to read.

**Acceptance Criteria:**

**Given** language selection is complete
**When** action plan playback begins
**Then** the Action Plan Model MCP is queried: `get_current_action_plan(farmer_id)`
**And** the TTS script version of the plan is retrieved

**Given** an action plan exists
**When** TTS playback starts
**Then** the plan is read with natural pacing: intro, issue 1, recommendation 1, pause, issue 2, etc.
**And** SSML tags control pauses, emphasis, and speed
**And** total duration is 2-3 minutes maximum

**Given** the action plan has multiple recommendations
**When** reading each section
**Then** there is a 1-second pause between sections
**And** "First..." "Second..." "Finally..." transitional phrases are used
**And** the farmer can interrupt at any time (see Story 7.5)

**Given** no action plan exists for this week
**When** the query returns empty
**Then** a friendly message plays: "You have no new recommendations this week. Your last delivery was excellent!"
**And** the option to hear previous week's plan is offered

**Given** playback completes
**When** the plan has been fully read
**Then** "That's your plan for this week. Press 1 to replay, 9 to end call."
**And** the menu allows farmer to choose next action

**Technical Notes:**
- TTS: Google Cloud TTS with SSML
- Max duration: 180 seconds (3 min)
- Speech rate: 0.9x for clarity
- Pauses: <break time="1s"/> between sections

---

#### Story 7.5: Navigation and Help Options

As a **farmer**,
I want to control playback and get help during the call,
So that I can replay sections I missed or exit when done.

**Acceptance Criteria:**

**Given** the action plan is playing
**When** the farmer presses 1 during playback
**Then** playback restarts from the beginning
**And** "Repeating from the start..." plays first

**Given** the action plan is playing
**When** the farmer presses 5 during playback
**Then** playback pauses
**And** "Paused. Press 5 to continue." plays
**And** call remains open for up to 30 seconds

**Given** the farmer presses 0 at any time
**When** the input is received
**Then** help menu plays: "For main menu, press star. To replay, press 1. To end call, press 9."
**And** help is in the farmer's selected language

**Given** the farmer presses 9 at any time
**When** the input is received
**Then** "Thank you for calling. Goodbye!" plays
**And** the call is ended gracefully
**And** call duration and outcome are logged

**Given** the farmer is silent for 60 seconds
**When** inactivity timeout occurs
**Then** "Are you still there? Press any key to continue." plays
**And** if no response in 15 seconds, call ends
**And** outcome is logged as "abandoned"

**Given** the call exceeds 5 minutes
**When** the time limit is reached
**Then** "Your call is about to end. Thank you for calling." plays
**And** the call ends after the message

**Technical Notes:**
- DTMF barge-in: enabled during playback
- Key mappings: 1=replay, 5=pause, 0=help, 9=end, *=main menu
- Inactivity timeout: 60 seconds
- Max call duration: 5 minutes
- Graceful hangup with goodbye message

---

### Epic 8: Voice Quality Advisor (Conversational AI)

#### Story 8.1: Conversational AI Service Setup

As a **platform operator**,
I want the Conversational AI service deployed with voice processing capabilities,
So that farmers can have interactive voice conversations about quality improvement.

**Acceptance Criteria:**

**Given** the Kubernetes cluster is running
**When** the Conversational AI service is deployed
**Then** the service starts successfully with health check endpoint returning 200
**And** Africa's Talking Voice API is configured for inbound calls
**And** speech-to-text (STT) provider is connected (Google Cloud Speech or Whisper)
**And** text-to-speech (TTS) provider is connected (Google Cloud TTS)
**And** OpenTelemetry traces are emitted for all calls

**Given** the service is running
**When** a call is received on the Voice Advisor number
**Then** the call is routed to the conversational AI handler
**And** a new conversation session is created
**And** the session tracks: call_id, farmer_id, turn_count, conversation_history

**Given** the service needs LLM capability
**When** the AI responds to farmer questions
**Then** Claude Sonnet is used for response generation
**And** MCP tools provide farmer context (Plantation, Collection, Knowledge, Action Plan)
**And** all LLM calls are traced via LangChain callbacks

**Given** external dependencies are unavailable
**When** STT, TTS, or LLM fails
**Then** graceful fallback is triggered (see Story 8.7)
**And** an alert is logged for monitoring

**Technical Notes:**
- Python FastAPI with async WebSocket support
- Africa's Talking for telephony
- Google Cloud Speech-to-Text v2 (Swahili model)
- Google Cloud TTS (Wavenet voices)
- Claude Sonnet for conversational AI
- Environment: farmer-power-{env} namespace

---

#### Story 8.2: Swahili Speech-to-Text

As a **farmer speaking Swahili**,
I want my speech accurately transcribed,
So that the AI understands my questions.

**Acceptance Criteria:**

**Given** a farmer speaks during the call
**When** audio is captured
**Then** audio is streamed to the STT provider in real-time
**And** transcription begins immediately (streaming mode)
**And** interim results are available for responsive UI

**Given** the farmer speaks Swahili
**When** transcription is performed
**Then** the Swahili language model (sw-KE) is used
**And** accuracy target is >85% for common tea/farming vocabulary
**And** agricultural terms are recognized correctly

**Given** the farmer speaks with a regional accent
**When** transcription is performed
**Then** the model adapts to Kenyan Swahili pronunciation
**And** common code-switching (Swahili/English mix) is handled

**Given** background noise is present
**When** audio is captured
**Then** noise reduction is applied before STT
**And** voice activity detection filters silence
**And** only speech segments are transcribed

**Given** STT returns low confidence (<0.6)
**When** transcription completes
**Then** the system flags the utterance as unclear
**And** a clarification prompt is triggered: "I didn't quite catch that. Could you repeat?"

**Given** STT fails completely
**When** the service is unavailable
**Then** fallback to DTMF-based interaction is offered
**And** SMS fallback is triggered (see Story 8.7)

**Technical Notes:**
- Google Cloud Speech-to-Text v2 (streaming)
- Model: sw-KE (Swahili - Kenya)
- Sample rate: 8kHz (telephony)
- Enhanced model for improved accuracy
- Phrase hints: tea, quality, primary, secondary, grade

---

#### Story 8.3: Intent Classification

As a **Conversational AI system**,
I want to classify farmer intents from their speech,
So that appropriate responses can be generated.

**Acceptance Criteria:**

**Given** a farmer's speech is transcribed
**When** intent classification runs
**Then** the intent is classified into categories: quality_question, action_plan_query, general_help, clarification, goodbye

**Given** the farmer asks "Why was my tea graded poorly?"
**When** classification runs
**Then** intent = "quality_question"
**And** entities extracted: time_reference="recent delivery"

**Given** the farmer asks "What should I do to improve?"
**When** classification runs
**Then** intent = "action_plan_query"
**And** the system fetches the farmer's current action plan

**Given** the farmer says "I don't understand"
**When** classification runs
**Then** intent = "clarification"
**And** the previous response is rephrased more simply

**Given** the farmer says "Goodbye" or "Asante"
**When** classification runs
**Then** intent = "goodbye"
**And** the call wrapping procedure is triggered

**Given** intent classification confidence is low (<0.5)
**When** the classifier is uncertain
**Then** a disambiguation question is asked: "Are you asking about your recent delivery or your weekly plan?"
**And** the response guides the farmer to clarify

**Technical Notes:**
- Intent classification: Claude Haiku (fast, cheap)
- Entity extraction: time_reference, topic, quantity
- Confidence threshold: 0.5 for disambiguation
- Intent history: tracked in conversation session

---

#### Story 8.4: Personalized Response Generation

As a **farmer**,
I want personalized answers based on my quality data,
So that advice is relevant to my specific situation.

**Acceptance Criteria:**

**Given** a farmer asks a quality question
**When** response generation begins
**Then** MCP tools are invoked to gather context:
  - `get_farmer_summary(farmer_id)` for profile and trend
  - `get_recent_quality_events(farmer_id, days=7)` for recent deliveries
  - `get_farmer_analyses(farmer_id, past_7_days)` for diagnoses
  - `get_current_action_plan(farmer_id)` for recommendations

**Given** context is gathered
**When** the LLM generates a response
**Then** the response references the farmer's actual data: "{farmer_name}, your last delivery was 65% primary..."
**And** specific issues are mentioned by name
**And** actionable advice is provided

**Given** the farmer's trend is declining
**When** response is generated
**Then** the AI acknowledges the trend: "I notice your quality has been decreasing lately..."
**And** encouragement is included: "But here's what you can do..."

**Given** the farmer is performing well
**When** they ask a question
**Then** the AI acknowledges success: "You're doing great! Your 85% primary rate is above average."
**And** tips for maintaining quality are offered

**Given** the response is generated
**When** it is finalized
**Then** the response is appropriate for spoken delivery (short sentences, simple words)
**And** the response is in the farmer's selected language
**And** response length is limited to 30 seconds of TTS

**Technical Notes:**
- LLM: Claude Sonnet with MCP tools
- Max response tokens: 150 (for natural speech)
- Language: farmer's pref_lang or session language
- Conversation history: passed to LLM for context

---

#### Story 8.5: Guided Dialogue Flow

As a **Conversational AI system**,
I want to guide conversations efficiently,
So that farmers get answers within the 3-minute limit.

**Acceptance Criteria:**

**Given** a conversation starts
**When** the greeting plays
**Then** the AI introduces itself: "I'm your Quality Advisor. How can I help you today?"
**And** the conversation turn counter starts at 1

**Given** the conversation proceeds
**When** each turn completes
**Then** the turn counter increments
**And** the turn is logged with: intent, response, duration

**Given** the conversation reaches turn 3
**When** the farmer continues
**Then** the AI gently guides toward closure: "Is there anything else quick I can help with?"
**And** turn 4 and 5 are available if needed

**Given** the conversation reaches turn 5
**When** the turn completes
**Then** the AI wraps up: "I hope that helped. Remember, you can call back anytime. Goodbye!"
**And** the call ends gracefully

**Given** the conversation exceeds 3 minutes
**When** the time limit approaches
**Then** a gentle warning plays: "We're almost out of time. Let me quickly summarize..."
**And** a brief summary of key points is provided
**And** the call wraps up

**Given** the farmer goes off-topic
**When** non-quality topics are detected
**Then** the AI politely redirects: "I'm here to help with tea quality. Is there something about your tea I can help with?"
**And** escalation to human is offered if farmer insists

**Technical Notes:**
- Max turns: 5
- Max duration: 3 minutes
- Turn tracking: conversation session state
- Off-topic detection: intent = "out_of_scope"

---

#### Story 8.6: Streaming Response Delivery

As a **farmer**,
I want to hear responses without long delays,
So that the conversation feels natural.

**Acceptance Criteria:**

**Given** the AI generates a response
**When** response generation begins
**Then** streaming mode is used for LLM output
**And** TTS synthesis starts as soon as the first sentence is complete
**And** audio playback begins while subsequent sentences are generated

**Given** streaming is active
**When** the farmer hears the response
**Then** the perceived latency is <2 seconds from end of farmer speech
**And** audio plays smoothly without stuttering

**Given** a sentence is complete
**When** TTS synthesis runs
**Then** SSML formatting is applied for natural prosody
**And** appropriate pauses are inserted between sentences
**And** emphasis is added for key words

**Given** the farmer interrupts during playback
**When** speech is detected mid-response
**Then** playback stops immediately (barge-in)
**And** the new farmer speech is transcribed
**And** the AI adapts to the interruption

**Given** network latency is high
**When** streaming cannot achieve <2s
**Then** a filler phrase plays: "Let me think about that..."
**And** the response begins as soon as available
**And** total perceived latency remains acceptable

**Technical Notes:**
- LLM streaming: enabled for Claude Sonnet
- TTS chunking: per-sentence
- Barge-in: voice activity detection
- Latency budget: 2 seconds total
- Buffer: 1 sentence ahead for smooth playback

---

#### Story 8.7: SMS Fallback Handling

As a **farmer whose speech wasn't understood**,
I want to receive an SMS with the information,
So that I still get help even if voice interaction fails.

**Acceptance Criteria:**

**Given** the AI cannot understand the farmer after 2 clarification attempts
**When** the third attempt fails
**Then** the AI offers SMS fallback: "I'm having trouble understanding. Would you like me to send you an SMS with your information?"

**Given** the farmer accepts SMS fallback (says yes or presses 1)
**When** fallback is triggered
**Then** the Notification Model is invoked
**And** an SMS is sent with: recent grade, primary %, and key action
**And** the call ends gracefully: "I've sent you an SMS. Goodbye!"

**Given** the farmer declines SMS fallback
**When** they indicate no (says no or presses 2)
**Then** the AI offers one more try: "Let's try once more. Please speak slowly."
**And** if still unsuccessful, escalation to human is offered

**Given** STT service is completely unavailable
**When** the call starts
**Then** the AI announces: "Our voice system is temporarily unavailable."
**And** SMS fallback is immediately offered
**And** the call is kept short (< 30 seconds)

**Given** LLM is unavailable
**When** response generation fails
**Then** a pre-recorded message plays: "I'm unable to answer right now. Let me send you an SMS."
**And** SMS fallback is triggered automatically
**And** the incident is logged for review

**Given** SMS fallback is triggered
**When** the SMS is sent
**Then** the SMS includes: farmer_name, last_grade, last_primary_%, ONE tip
**And** the SMS ends with: "Call back later for more help."
**And** the SMS uses the farmer's pref_lang

**Technical Notes:**
- SMS via Notification Model gRPC
- Fallback SMS template: pre-approved, 160 chars max
- Escalation: flag for human callback (if configured)
- Logging: failed_conversation events for analysis

---

### Epic 9: Platform Admin Portal

Internal Farmer Power team can onboard new factories, manage users across all factories, and monitor platform health. This is the internal operations portal.

**Related ADRs:** ADR-002 (Frontend Architecture), ADR-003 (Identity & Access Management)

**Scope:**
- Platform admin web application (separate from factory-portal)
- Factory onboarding workflow
- Cross-factory user management
- Platform health dashboard
- Access restricted to internal team (VPN/internal network)

---

#### Story 9.1: Platform Admin Application Scaffold

As a **platform developer**,
I want the Platform Admin React application scaffolded with routing and layout,
So that internal team screens can be built.

**Acceptance Criteria:**

**Given** the web folder structure exists
**When** I create `web/platform-admin/`
**Then** Vite + React + TypeScript project is initialized
**And** `@fp/ui-components` and `@fp/auth` are configured as dependencies
**And** ESLint and Prettier are configured

**Given** the project is scaffolded
**When** I configure routing
**Then** React Router v6 is configured with:
  - `/dashboard` (Platform Overview)
  - `/factories` (Factory List)
  - `/factories/new` (Factory Onboarding)
  - `/users` (User Management)
**And** Routes require `platform_admin` role

**Given** the app is built
**When** I access the application
**Then** It's only accessible from internal network/VPN
**And** Separate B2C application registration is used
**And** No factory-specific branding (Farmer Power internal theme)

**Technical Notes:**
- Location: `web/platform-admin/`
- Deployment: `admin.farmerpower.co.ke` (internal access only)
- Reference: ADR-002 for folder structure

**Dependencies:**
- Story 0.5.1: Shared Component Library
- Story 0.5.3: Shared Auth Library

**Story Points:** 3

---

#### Story 9.2: Factory Onboarding Wizard

As a **Platform Administrator**,
I want a wizard to onboard new factories to the platform,
So that factory setup is consistent and complete.

**Acceptance Criteria:**

**Given** I navigate to Factory Onboarding
**When** I start the wizard
**Then** Step 1 collects: factory name, location, contact person, email
**And** Step 2 collects: collection points (name, GPS coordinates)
**And** Step 3 configures: default payment policy, SMS templates
**And** Step 4 creates: initial admin user for factory

**Given** I complete the wizard
**When** I click "Create Factory"
**Then** Factory record is created in Plantation Model
**And** Factory admin user is created in Azure AD B2C
**And** Welcome email is sent with login credentials
**And** Confirmation page shows summary and next steps

**Given** I need to resume onboarding
**When** I save draft partway through
**Then** Draft is saved and can be resumed later
**And** Draft list shows incomplete onboardings

**Technical Notes:**
- Multi-step form with validation per step
- API: POST /api/admin/factories (creates factory + user)
- User creation via Microsoft Graph API
- Email via Notification Model

**Dependencies:**
- Story 9.1: Platform Admin Application Scaffold
- Story 1.2: Factory and Collection Point Management

**Story Points:** 5

---

#### Story 9.3: User Management Dashboard

As a **Platform Administrator**,
I want to view and manage users across all factories,
So that I can support user administration tasks.

**Acceptance Criteria:**

**Given** I navigate to User Management
**When** the page loads
**Then** I see a table of all platform users
**And** Columns show: name, email, factory, role, last login, status
**And** Search and filter by factory, role, status are available

**Given** I need to create a new user
**When** I click "Add User"
**Then** Form collects: name, email, factory (dropdown), role (dropdown)
**And** User is created in Azure AD B2C
**And** Welcome email is sent automatically

**Given** I need to modify a user
**When** I click on a user row
**Then** I can edit: role, factory assignment
**And** I can reset password (sends reset email)
**And** I can disable/enable account

**Given** a user is locked out
**When** I reset their password
**Then** Temporary password is generated
**And** Email is sent with reset instructions
**And** Audit log captures who performed the reset

**Technical Notes:**
- Users stored in Azure AD B2C (not local DB)
- Microsoft Graph API for user operations
- Audit log to MongoDB for compliance

**Dependencies:**
- Story 9.1: Platform Admin Application Scaffold
- Story 0.5.2: Azure AD B2C Configuration

**Story Points:** 5

---

#### Story 9.4: Platform Health Dashboard

As a **Platform Administrator**,
I want to see platform-wide health metrics and factory statistics,
So that I can monitor operations and identify issues.

**Acceptance Criteria:**

**Given** I navigate to the Platform Dashboard
**When** the page loads
**Then** I see: total factories, total farmers, active users (24h)
**And** System health indicators: API latency, error rate, queue depth
**And** Map shows factory locations with status indicators

**Given** I want to see factory details
**When** I click on a factory card/pin
**Then** I see: farmer count, daily delivery volume, quality trend
**And** Link to impersonate factory admin (for support)
**And** Recent activity log for that factory

**Given** there are system issues
**When** error rate exceeds threshold
**Then** Alert banner shows on dashboard
**And** Affected services are highlighted
**And** Recent error samples are shown

**Technical Notes:**
- Aggregated metrics from OpenTelemetry
- Health checks from each service
- Map: Leaflet with Kenya regions

**Dependencies:**
- Story 9.1: Platform Admin Application Scaffold
- Story 3.1: Dashboard BFF Setup (for health endpoints)

**Story Points:** 5

---

### Epic 10: Regulator Dashboard

Tea Board of Kenya officials can view national-level quality intelligence. This dashboard is completely isolated from factory data for security.

**Related ADRs:** ADR-002 (Frontend Architecture), ADR-003 (Identity & Access Management)

**Scope:**
- Regulator web application (completely separate from factory systems)
- National quality overview with regional breakdown
- Leaf type distribution analysis
- Export readiness indicators
- No individual farmer PII visible

---

#### Story 10.1: Regulator Application Scaffold

As a **platform developer**,
I want the Regulator Dashboard React application scaffolded,
So that TBK officials have a secure, isolated portal.

**Acceptance Criteria:**

**Given** the web folder structure exists
**When** I create `web/regulator/`
**Then** Vite + React + TypeScript project is initialized
**And** `@fp/ui-components` and `@fp/auth` are configured as dependencies
**And** Separate authentication configuration (B2B federation ready)

**Given** the application is deployed
**When** TBK officials access the portal
**Then** It's hosted on separate subdomain: `regulator.farmerpower.co.ke`
**And** No shared runtime state with factory applications
**And** All data is pre-aggregated (no individual farmer data)

**Given** authentication is configured
**When** regulator users sign in
**Then** They use TBK Azure AD tenant (B2B federation)
**And** No access to factory-level or farmer-level data
**And** Only `regulator` role has access

**Technical Notes:**
- Location: `web/regulator/`
- Separate B2C application registration
- B2B federation with TBK Azure AD (future)
- Reference: ADR-002, ADR-003 for isolation requirements

**Dependencies:**
- Story 0.5.1: Shared Component Library
- Story 0.5.3: Shared Auth Library

**Story Points:** 3

---

#### Story 10.2: National Quality Overview

As a **Tea Board of Kenya official**,
I want to see national-level quality metrics,
So that I can monitor tea quality across all participating factories.

**Acceptance Criteria:**

**Given** I am logged in as regulator
**When** I view the National Overview page
**Then** I see: total participating factories, total farmers, total volume (kg)
**And** National average quality grade is shown
**And** Trend shows quality over time (weekly/monthly)

**Given** I want to understand quality distribution
**When** I view the quality breakdown
**Then** Chart shows: % Primary, % Secondary by region
**And** Comparison to previous period (week/month/quarter)
**And** Target thresholds are marked on chart

**Given** I need to identify problem areas
**When** quality falls below threshold
**Then** Regions are highlighted with warning indicator
**And** I can click to see regional details
**And** No individual factory or farmer names are shown

**Technical Notes:**
- API: Aggregated data only (no factory_id in response)
- Pre-computed aggregations (not real-time queries)
- Data anonymized at API layer

**Dependencies:**
- Story 10.1: Regulator Application Scaffold

**Story Points:** 5

---

#### Story 10.3: Regional Quality Comparison

As a **Tea Board of Kenya official**,
I want to compare quality metrics across regions,
So that I can target interventions and policy.

**Acceptance Criteria:**

**Given** I navigate to Regional Comparison
**When** the page loads
**Then** Map of Kenya shows regions color-coded by quality
**And** Table shows: region name, avg grade, volume, trend
**And** Sorting and filtering by metric is available

**Given** I select a region
**When** I view region details
**Then** I see: factory count (anonymized), farmer count, quality trend
**And** Seasonal pattern analysis is shown
**And** Weather impact correlation (if significant)

**Given** I want to export data
**When** I click "Export Report"
**Then** PDF/Excel report is generated with selected metrics
**And** Report is branded with TBK logo
**And** Data export is logged for audit

**Technical Notes:**
- Map: Choropleth with Kenya county boundaries
- Export: Server-side PDF generation
- No factory identifiers in export

**Dependencies:**
- Story 10.1: Regulator Application Scaffold
- Story 10.2: National Quality Overview

**Story Points:** 5

---

#### Story 10.4: Leaf Type Distribution & Export Readiness

As a **Tea Board of Kenya official**,
I want to analyze leaf type distribution and export readiness,
So that I can assess Kenya's tea export potential.

**Acceptance Criteria:**

**Given** I navigate to Leaf Type Distribution
**When** the page loads
**Then** I see: national breakdown by leaf_type (Purple Leaf, Fine, Coarse, etc.)
**And** Trend over time shows seasonal patterns
**And** Comparison to TBK quality targets

**Given** I view Export Readiness
**When** I analyze the data
**Then** I see: % meeting export grade thresholds
**And** Projection based on current trends
**And** Regional breakdown of export-ready volume

**Given** I need policy insights
**When** I view recommendations panel
**Then** AI-generated insights highlight:
  - Regions with improvement potential
  - Seasonal factors affecting quality
  - Suggested intervention focus areas
**And** Insights are based on aggregated data only

**Technical Notes:**
- Leaf type categories per TBK specification
- Export thresholds: configurable in admin
- AI insights: pre-generated daily (not real-time LLM calls)

**Dependencies:**
- Story 10.1: Regulator Application Scaffold
- Story 10.2: National Quality Overview

**Story Points:** 5

---

### Epic 11: Registration Kiosk PWA

Registration clerks at collection points can enroll new farmers using dedicated tablets. The application works offline for rural areas with poor connectivity.

**Related ADRs:** ADR-002 (Frontend Architecture), ADR-003 (Identity & Access Management)

**Scope:**
- Progressive Web App (PWA) for offline-first operation
- Farmer registration workflow
- Collection point assignment
- ID card printing support
- Background sync when connectivity restored

---

#### Story 11.1: Registration Kiosk Application Scaffold

As a **platform developer**,
I want the Registration Kiosk PWA scaffolded with offline support,
So that registration works in rural areas with poor connectivity.

**Acceptance Criteria:**

**Given** the web folder structure exists
**When** I create `web/registration-kiosk/`
**Then** Vite + React + TypeScript project is initialized with PWA plugin
**And** Service worker is configured for offline-first
**And** App manifest enables "Add to Home Screen"

**Given** the PWA is installed on a tablet
**When** network is unavailable
**Then** App shell loads from cache
**And** "Offline mode" indicator is shown
**And** All registration functionality works

**Given** authentication is needed
**When** clerk logs in on kiosk device
**Then** Device Code Flow is used (no redirect)
**And** Session persists for 8 hours
**And** Auto-refresh keeps session alive

**Technical Notes:**
- Location: `web/registration-kiosk/`
- PWA: Workbox for service worker
- Offline storage: IndexedDB
- Auth: Device Code Flow (ADR-003)
- Reference: ADR-002 for PWA requirements

**Dependencies:**
- Story 0.5.1: Shared Component Library
- Story 0.5.3: Shared Auth Library

**Story Points:** 5

---

#### Story 11.2: Farmer Registration Workflow

As a **Registration Clerk**,
I want to register new farmers with their details,
So that they can be tracked in the quality system.

**Acceptance Criteria:**

**Given** I open the registration form
**When** I enter farmer details
**Then** Form collects: name, phone, national_id, farm_size, location
**And** GPS coordinates can be captured from device
**And** Phone number is validated (Kenya format)

**Given** I submit the registration
**When** online
**Then** Farmer is created immediately via API
**And** Farmer ID is generated (e.g., WM-4521)
**And** Confirmation screen shows farmer ID

**Given** I submit the registration
**When** offline
**Then** Registration is queued in IndexedDB
**And** Temporary ID is shown: "Pending sync"
**And** Queue count badge shows on home screen

**Given** I have queued registrations
**When** network is restored
**Then** Background sync uploads pending registrations
**And** Temporary IDs are replaced with real IDs
**And** Notification confirms sync complete

**Technical Notes:**
- Form: React Hook Form + Zod validation
- Offline queue: IndexedDB with queue status
- Sync: Background Sync API / periodic check
- API: POST /api/farmers

**Dependencies:**
- Story 11.1: Registration Kiosk Application Scaffold
- Story 1.3: Farmer Registration (API)

**Story Points:** 5

---

#### Story 11.3: Collection Point Assignment

As a **Registration Clerk**,
I want to assign farmers to their collection point,
So that deliveries are tracked correctly.

**Acceptance Criteria:**

**Given** I am registering a farmer
**When** I reach collection point step
**Then** Dropdown shows collection points for this factory
**And** Collection points are cached offline
**And** Default is clerk's assigned collection point

**Given** the farmer needs a different collection point
**When** I select from the list
**Then** Map shows collection point location
**And** Distance from farmer's GPS is calculated
**And** Warning if distance > 10km (unusual)

**Given** collection point data is stale
**When** app syncs
**Then** Collection point list is refreshed
**And** Changes are merged (new points added, closed points flagged)
**And** Last sync time is shown in UI

**Technical Notes:**
- Collection points cached in IndexedDB
- Sync on login and every 24 hours
- Distance: Haversine formula (client-side)

**Dependencies:**
- Story 11.1: Registration Kiosk Application Scaffold
- Story 1.2: Factory and Collection Point Management

**Story Points:** 3

---

#### Story 11.4: Farmer ID Card Printing

As a **Registration Clerk**,
I want to print a farmer ID card after registration,
So that farmers have proof of registration.

**Acceptance Criteria:**

**Given** registration is complete
**When** I click "Print ID Card"
**Then** ID card preview shows: farmer name, ID, collection point, QR code
**And** QR code contains farmer_id for quick lookup
**And** Print dialog opens with correct page size (ID card format)

**Given** printer is connected
**When** I confirm print
**Then** ID card prints on configured printer
**And** Print success is logged
**And** Reprint option is available from farmer list

**Given** printer is not connected
**When** I try to print
**Then** Error message shows with troubleshooting steps
**And** Option to queue for later printing
**And** "View digital ID" alternative is offered

**Given** registration was completed offline
**When** sync completes and real ID is assigned
**Then** Print option becomes available
**And** ID card shows final farmer_id

**Technical Notes:**
- Web Print API (window.print)
- ID card template: CSS @media print
- QR code: qrcode.react library
- Thermal printer support: ESC/POS if needed

**Dependencies:**
- Story 11.2: Farmer Registration Workflow

**Story Points:** 3

---

## Summary

### Epic and Story Counts

| Epic | Stories | FRs/ADRs Covered |
|------|---------|------------------|
| Epic 0: Platform Infrastructure Foundation | 1 | AR1-AR12 |
| Epic 0.5: Frontend & Identity Infrastructure | 5 | ADR-002, ADR-003 |
| Epic 1: Farmer Registration & Data Foundation | 6 | FR34-FR38 |
| Epic 2: Quality Data Ingestion | 8 | FR15-FR23, FR58-FR61 |
| Epic 3: Factory Manager Dashboard | 12 | FR9-FR14, ADR-002 |
| Epic 4: Farmer SMS Feedback | 7 | FR1-FR4, FR8, FR39-FR44 |
| Epic 5: Quality Diagnosis AI | 9 | FR24-FR28, FR45-FR49 |
| Epic 6: Weekly Action Plans | 6 | FR29-FR33 |
| Epic 7: Voice IVR Experience | 5 | FR5-FR7 |
| Epic 8: Voice Quality Advisor | 7 | FR50-FR57 |
| Epic 9: Platform Admin Portal | 4 | ADR-002, ADR-003 |
| Epic 10: Regulator Dashboard | 4 | ADR-002, ADR-003 |
| Epic 11: Registration Kiosk PWA | 4 | ADR-002, ADR-003 |
| **Total** | **78 stories** | **61 FRs + 3 ADRs** |

### Story Index

**Epic 0: Platform Infrastructure Foundation**
- Story 0.1: MCP gRPC Infrastructure

**Epic 0.5: Frontend & Identity Infrastructure**
- Story 0.5.1: Shared Component Library Setup
- Story 0.5.2: Azure AD B2C Configuration
- Story 0.5.3: Shared Auth Library
- Story 0.5.4: Factory Portal Scaffold
- Story 0.5.5: BFF Authentication Middleware

**Epic 1: Farmer Registration & Data Foundation**
- Story 1.1: Plantation Model Service Setup
- Story 1.2: Factory and Collection Point Management
- Story 1.3: Farmer Registration
- Story 1.4: Farmer Performance History Structure
- Story 1.5: Farmer Communication Preferences
- Story 1.6: TBK Quality Grading
- Story 1.7: Plantation Model MCP Server

**Epic 2: Quality Data Ingestion**
- Story 2.1: Collection Model Service Setup
- Story 2.2: END_BAG Event Ingestion API
- Story 2.3: TBK Grading Result Storage
- Story 2.4: Batch Upload for Intermittent Connectivity
- Story 2.5: POOR_QUALITY_DETECTED Event Handling
- Story 2.6: Weather Data Pull Mode
- Story 2.7: Image Evidence Storage
- Story 2.8: Collection Model MCP Server

**Epic 3: Factory Manager Dashboard**
- Story 3.1: Dashboard BFF (Backend for Frontend) Setup
- Story 3.2: Farmer Quality Overview Grid
- Story 3.3: Farmer Categorization (Action Needed/Watch/Wins)
- Story 3.4: Dashboard Filtering
- Story 3.5: One-Click Farmer Contact
- Story 3.6: Daily Report Auto-Generation
- Story 3.7: Dashboard Performance Optimization
- Story 3.8: Factory Owner ROI Dashboard
- Story 3.9: Factory Admin Settings UI
- Story 3.10: Command Center Screen Implementation
- Story 3.11: Farmer Detail Screen
- Story 3.12: SMS Preview and Compose

**Epic 4: Farmer SMS Feedback**
- Story 4.1: Notification Model Service Setup
- Story 4.2: SMS Message Generation
- Story 4.3: SMS Cost Optimization
- Story 4.4: SMS Delivery Assurance
- Story 4.5: Lead Farmer Escalation
- Story 4.6: Inbound Keyword Handling
- Story 4.7: Group and Regional Messaging

**Epic 5: Quality Diagnosis AI**
- Story 5.1: Knowledge Model Service Setup
- Story 5.2: Event Aggregation Engine
- Story 5.3: Triage Agent
- Story 5.4: Disease Detection Agent
- Story 5.5: Weather Impact Analyzer
- Story 5.6: Technique Assessment Agent
- Story 5.7: Trend Analysis Agent
- Story 5.8: RAG Knowledge Base
- Story 5.9: Knowledge Model MCP Server

**Epic 6: Weekly Action Plans**
- Story 6.1: Action Plan Model Service Setup
- Story 6.2: Weekly Action Plan Generation
- Story 6.3: Farm-Scale-Aware Recommendations
- Story 6.4: Dual-Format Output (Report + SMS)
- Story 6.5: Multilingual Translation
- Story 6.6: Action Plan MCP Server

**Epic 7: Voice IVR Experience**
- Story 7.1: Voice IVR Service Setup
- Story 7.2: Caller ID Farmer Identification
- Story 7.3: Language Selection Menu
- Story 7.4: Action Plan TTS Playback
- Story 7.5: Navigation and Help Options

**Epic 8: Voice Quality Advisor (Conversational AI)**
- Story 8.1: Conversational AI Service Setup
- Story 8.2: Swahili Speech-to-Text
- Story 8.3: Intent Classification
- Story 8.4: Personalized Response Generation
- Story 8.5: Guided Dialogue Flow
- Story 8.6: Streaming Response Delivery
- Story 8.7: SMS Fallback Handling

**Epic 9: Platform Admin Portal**
- Story 9.1: Platform Admin Application Scaffold
- Story 9.2: Factory Onboarding Wizard
- Story 9.3: User Management Dashboard
- Story 9.4: Platform Health Dashboard

**Epic 10: Regulator Dashboard**
- Story 10.1: Regulator Application Scaffold
- Story 10.2: National Quality Overview
- Story 10.3: Regional Quality Comparison
- Story 10.4: Leaf Type Distribution & Export Readiness

**Epic 11: Registration Kiosk PWA**
- Story 11.1: Registration Kiosk Application Scaffold
- Story 11.2: Farmer Registration Workflow
- Story 11.3: Collection Point Assignment
- Story 11.4: Farmer ID Card Printing

---

*Generated: 2025-12-26 (Updated with ADR-002 & ADR-003 impact)*
